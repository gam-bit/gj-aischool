{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_wordvec_and_visualization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ymJ6CS5aKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "8570c404-887e-4a3c-8043-3f1bb059ac3b"
      },
      "source": [
        "# google drive 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6AJLY965b9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoK6tLFR7-Aj",
        "colab_type": "text"
      },
      "source": [
        "# 이미 만들어진 모델 가지고와서 쓰기 \n",
        "---\n",
        "# 1. Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzhOcRr-6Nrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# 변환을 원하는 텍스트\n",
        "\n",
        "token = Tokenizer()\n",
        "text = \"hello family parents sister\"\n",
        "token.fit_on_texts([text])\n",
        "word_count = len(token.word_index) # unique한 단어 수"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCu-hzhr40xB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7cdc5291-b300-45a7-9967-c2c8c93a4fe0"
      },
      "source": [
        "f = open('glove.6B.50d.txt', encoding='utf-8')\n",
        "\n",
        "word_vectors = {} # 단어의 임베딩 벡터가 들어 있음 (key: 단어/ value: 임베딩 벡터)\n",
        "\n",
        "for line in f:\n",
        "  word_vector = line.split()\n",
        "  word_vectors[word_vector[0]] = word_vector[1:] # word_vector[0] : word\n",
        "  \n",
        "print(word_vectors['apple'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.52042', '-0.8314', '0.49961', '1.2893', '0.1151', '0.057521', '-1.3753', '-0.97313', '0.18346', '0.47672', '-0.15112', '0.35532', '0.25912', '-0.77857', '0.52181', '0.47695', '-1.4251', '0.858', '0.59821', '-1.0903', '0.33574', '-0.60891', '0.41742', '0.21569', '-0.07417', '-0.5822', '-0.4502', '0.17253', '0.16448', '-0.38413', '2.3283', '-0.66682', '-0.58181', '0.74389', '0.095015', '-0.47865', '-0.84591', '0.38704', '0.23693', '-1.5523', '0.64802', '-0.16521', '-1.4719', '-0.16224', '0.79857', '0.97391', '0.40027', '-0.21912', '-0.30938', '0.26581']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI1w-3ug5gbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "# 가져온 text 임베딩 처리하기---------------------------------------------------\n",
        "\n",
        "matrix = np.zeros((word_count, 50)) # 50차원 임베딩 벡터 데이터를 사용했음(glove.6B.50d.txt) \n",
        "\n",
        "\n",
        "# 없는 단어에 대한 예외처리가 이 부분에서 필요함\n",
        "\n",
        "for word, i in token.word_index.items(): \n",
        "  matrix[i-1] = np.array(word_vectors[word])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_count, 50, weights=[matrix])) # Embedding Layer\n",
        "                                                       # weights을 쓰면 embedding vector를 set to be frozen\n",
        "                                                       # -> not updated during training"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GATE--Z0Zo2R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Embedding은 단어를 밀집 벡터로 만드는 것이다. \n",
        "인공 신경망 용어에서 embedding layer를 만드는 역할을 한다.\n",
        "Embedding()은 정수 인코딩이 된 단어들을 입력받아서 임베딩을 수행한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_13CQDb7u0x",
        "colab_type": "text"
      },
      "source": [
        "# 2. Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IBSzfBA7RTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "matrix = np.zeros((word_count, 300)) \n",
        "\n",
        "\n",
        "# 없는 단어에 대한 예외처리가 이 부분에서 필요함\n",
        "\n",
        "for word, i in token.word_index.items():\n",
        "  matrix[i] = np.array(word_vectors[word])\n",
        "\n",
        "# 예시일 뿐 실제 사용가능한 모델은 아님\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_count, 50, weights=[matrix])) # Embedding Layer\n",
        "# 이후 dense layer로 갈 때 flatten layer가 필요(차원맞추기위함)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaDOdjZ5Mvt7",
        "colab_type": "text"
      },
      "source": [
        "## - Word2Vec 시각화\n",
        "\n",
        "- `07_Embedding_Word2Vec.ipynb` 코드 사용\n",
        "\n",
        "- [Embedding Projector](https://projector.tensorflow.org/)에 .tsv file을 넣어서 임베딩한 단어들을 시각화할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiefkMvdNSHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "775cf70a-4a54-44fa-8be9-583279f0f640"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import csv\n",
        "import re\n",
        "\n",
        "def open_csv():\n",
        "    # csv파일을 연다!\n",
        "    f = open('IMDB Dataset.csv', 'r', encoding='utf-8')\n",
        "    csvreader = csv.reader(f)\n",
        "    \n",
        "    doc_list = []\n",
        "\n",
        "    next(csvreader)\n",
        "    for f in csvreader:\n",
        "        line = re.compile(\"[^\\w]\").sub(' ', f[0].lower())\n",
        "        doc_list.append(line.split())\n",
        "\n",
        "    return doc_list\n",
        "\n",
        "doc_list = open_csv()\n",
        "print(doc_list[:3])\n",
        "\n",
        "model = Word2Vec(sentences=doc_list, size=100, window=3, min_count=3, workers=4, sg=0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'br', 'br', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'br', 'br', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'br', 'br', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'doesn', 't', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side'], ['a', 'wonderful', 'little', 'production', 'br', 'br', 'the', 'filming', 'technique', 'is', 'very', 'unassuming', 'very', 'old', 'time', 'bbc', 'fashion', 'and', 'gives', 'a', 'comforting', 'and', 'sometimes', 'discomforting', 'sense', 'of', 'realism', 'to', 'the', 'entire', 'piece', 'br', 'br', 'the', 'actors', 'are', 'extremely', 'well', 'chosen', 'michael', 'sheen', 'not', 'only', 'has', 'got', 'all', 'the', 'polari', 'but', 'he', 'has', 'all', 'the', 'voices', 'down', 'pat', 'too', 'you', 'can', 'truly', 'see', 'the', 'seamless', 'editing', 'guided', 'by', 'the', 'references', 'to', 'williams', 'diary', 'entries', 'not', 'only', 'is', 'it', 'well', 'worth', 'the', 'watching', 'but', 'it', 'is', 'a', 'terrificly', 'written', 'and', 'performed', 'piece', 'a', 'masterful', 'production', 'about', 'one', 'of', 'the', 'great', 'master', 's', 'of', 'comedy', 'and', 'his', 'life', 'br', 'br', 'the', 'realism', 'really', 'comes', 'home', 'with', 'the', 'little', 'things', 'the', 'fantasy', 'of', 'the', 'guard', 'which', 'rather', 'than', 'use', 'the', 'traditional', 'dream', 'techniques', 'remains', 'solid', 'then', 'disappears', 'it', 'plays', 'on', 'our', 'knowledge', 'and', 'our', 'senses', 'particularly', 'with', 'the', 'scenes', 'concerning', 'orton', 'and', 'halliwell', 'and', 'the', 'sets', 'particularly', 'of', 'their', 'flat', 'with', 'halliwell', 's', 'murals', 'decorating', 'every', 'surface', 'are', 'terribly', 'well', 'done'], ['i', 'thought', 'this', 'was', 'a', 'wonderful', 'way', 'to', 'spend', 'time', 'on', 'a', 'too', 'hot', 'summer', 'weekend', 'sitting', 'in', 'the', 'air', 'conditioned', 'theater', 'and', 'watching', 'a', 'light', 'hearted', 'comedy', 'the', 'plot', 'is', 'simplistic', 'but', 'the', 'dialogue', 'is', 'witty', 'and', 'the', 'characters', 'are', 'likable', 'even', 'the', 'well', 'bread', 'suspected', 'serial', 'killer', 'while', 'some', 'may', 'be', 'disappointed', 'when', 'they', 'realize', 'this', 'is', 'not', 'match', 'point', '2', 'risk', 'addiction', 'i', 'thought', 'it', 'was', 'proof', 'that', 'woody', 'allen', 'is', 'still', 'fully', 'in', 'control', 'of', 'the', 'style', 'many', 'of', 'us', 'have', 'grown', 'to', 'love', 'br', 'br', 'this', 'was', 'the', 'most', 'i', 'd', 'laughed', 'at', 'one', 'of', 'woody', 's', 'comedies', 'in', 'years', 'dare', 'i', 'say', 'a', 'decade', 'while', 'i', 've', 'never', 'been', 'impressed', 'with', 'scarlet', 'johanson', 'in', 'this', 'she', 'managed', 'to', 'tone', 'down', 'her', 'sexy', 'image', 'and', 'jumped', 'right', 'into', 'a', 'average', 'but', 'spirited', 'young', 'woman', 'br', 'br', 'this', 'may', 'not', 'be', 'the', 'crown', 'jewel', 'of', 'his', 'career', 'but', 'it', 'was', 'wittier', 'than', 'devil', 'wears', 'prada', 'and', 'more', 'interesting', 'than', 'superman', 'a', 'great', 'comedy', 'to', 'go', 'see', 'with', 'friends']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5GOcDxiMxl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 모델저장\n",
        "# model.wv.save_word2vec_format('imdb_w2v')\n",
        "# # 모델불러오기\n",
        "# imdb_model = KeyedVectors.load_word2vec_format(\"imdb_w2v\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bnCzNcU7LDZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le8ih2RwNc7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "ffe2d7c4-a7d2-4b41-dc46-af7564f18c74"
      },
      "source": [
        "# .tsv file로 변경해서 저장\n",
        "# -> google embedding projector에서 3차원으로(pca로 차원 축소한 것) 단어들의 분포를 확인할 수 있다.\n",
        "!python -m gensim.scripts.word2vec2tensor --input imdb_w2v --output imdb_w2v"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 09:06:32,335 - word2vec2tensor - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/word2vec2tensor.py --input imdb_w2v --output imdb_w2v\n",
            "2020-07-29 09:06:32,335 - utils_any2vec - INFO - loading projection weights from imdb_w2v\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-07-29 09:06:37,806 - utils_any2vec - INFO - loaded (50964, 100) matrix from imdb_w2v\n",
            "2020-07-29 09:06:43,730 - word2vec2tensor - INFO - 2D tensor file saved to imdb_w2v_tensor.tsv\n",
            "2020-07-29 09:06:43,732 - word2vec2tensor - INFO - Tensor metadata file saved to imdb_w2v_metadata.tsv\n",
            "2020-07-29 09:06:43,744 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHBzf3-q4Vhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU4BUisJ4V2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzPlmRvq4V6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeCWnbF94V9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdGLbQkX4WAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lp6i9t04WE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y78kgBmY4WHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZKFumQQ4WJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}