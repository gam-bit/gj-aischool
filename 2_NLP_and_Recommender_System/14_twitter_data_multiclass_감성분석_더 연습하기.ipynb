{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_twitter data_감성분석.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb8k9xrfE5l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Flatten, Concatenate, Input, Dropout, SimpleRNN\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from  nltk.stem import SnowballStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrzFe54gN4XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giO209zmFMOq",
        "colab_type": "text"
      },
      "source": [
        "# [캐글 tweet-sentiment-data](https://www.kaggle.com/maxjon/complete-tweet-sentiment-extraction-data/)를 이용한 감성분석 \n",
        "\n",
        "\n",
        "## 1. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-PA15RANYo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5f9c4d84-0f49-40bd-ef6d-3a105a5fe084"
      },
      "source": [
        "# 데이터 로드---------------------------------------\n",
        "tweet_data = pd.read_csv('./data/tweet_dataset.csv')\n",
        "# tweet_data.head()\n",
        "tweet = tweet_data[['text', 'sentiment']]\n",
        "\n",
        "# print(tweet.sentiment.unique(), '→', tweet.sentiment.nunique())  \n",
        "# print(tweet.isna().sum()) # text에 66개의 null data 있음\n",
        "print(\"# loaded data\")\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 전처리-------------------------------------\n",
        "tweet['text'] = tweet['text'].apply(lambda x: str(x).lower())\n",
        "tweet['text'] = tweet['text'].str.replace(r'[^\\w]', ' ')\n",
        "tweet['text'] = tweet['text'].replace('', np.nan)\n",
        "\n",
        "y_cate_list = pd.factorize(tweet['sentiment'])[1]\n",
        "tweet['senti_label'] = pd.factorize(tweet['sentiment'])[0]\n",
        "\n",
        "tweet = tweet.dropna(how='any', axis=0)\n",
        "tweet = tweet[tweet['text'] != 'nan']\n",
        "print('# preprocessing done')\n",
        "\n",
        "\n",
        "# split---------------------------------------------\n",
        "txt_train, txt_test, y_train, y_test = train_test_split(tweet['text'], tweet['senti_label'], test_size=0.2, shuffle=True, random_state=1234)\n",
        "print('# split done')\n",
        "\n",
        "# y OHE-------------------------------------\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "# 토큰화--------------------------------------------\n",
        "stopwords = ['a', 'an', 'in', 'on', 'and', 'for', 'the', 's', 'to', 'is', 'with', 'of', 'you',\n",
        "             'at', 'that', 'what', 'this', 'be', 'your', 't', 'it', 'from', 'are', 'about', 'as', 'i', 'my']\n",
        "\n",
        "X_train = []\n",
        "for stc in txt_train:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_train.append(token)\n",
        "\n",
        "X_test = []\n",
        "for stc in txt_test:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_test.append(token)\n",
        "\n",
        "print('# tokenization done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# loaded data\n",
            "# preprocessing done\n",
            "# split done\n",
            "# tokenization done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYbpBWULS8dn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "0bcad172-2bbc-4a2f-a51d-e265a08a1673"
      },
      "source": [
        "# 정수 인코딩 이전 과정\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# > 단어 개수 확인\n",
        "print(\"전체 단어 개수:\", len(tokenizer.word_index))\n",
        "print(\"빈도수 3이상인 단어 개수:\", len([token for token, count in tokenizer.word_counts.items() if count >= 3]))\n",
        "print(\"빈도수 4이상인 단어 개수:\", len([token for token, count in tokenizer.word_counts.items() if count >= 4]))\n",
        "plt.subplots()\n",
        "plt.hist(list(tokenizer.word_counts.values()))\n",
        "plt.subplots()\n",
        "plt.boxplot(list(tokenizer.word_counts.values()));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 단어 개수: 29043\n",
            "빈도수 3이상인 단어 개수: 7772\n",
            "빈도수 4이상인 단어 개수: 6012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD6CAYAAABZAsshAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUFklEQVR4nO3cfYxdd33n8fdnnQcQ0Nohs1HWNmtDvapc1DXpbEhVVLGgOk76h4MUsc5KjcVGdXdJJNB2JZxW2qRAJFgJkKKlQUHxxmlZnGwAxWrNum6IhPgjDw44D04aMiRBsWViN84DCCls0u/+cX8Tbt0Zz/w845k79fslXd1zv+d3zvme42t/fM8596aqkCSpx79Y7AYkSUuP4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSeo2Y3gkeUuSB5M8kuRgkj9r9bVJHkgykeTOJOe0+rnt9USbv2ZoXde3+lNJLh2qb2q1iSTb5383JUnzKTN9zyNJgLdV1c+SnA18D/gE8F+Bb1bVriRfAR6pqluSfBz4zar6z0m2AB+pqv+QZD3wdeBi4F8Bfwv8m7aZHwK/BxwCHgKuqqonTtbX+eefX2vWrDm1vZakM9TDDz/891U1Ntf1nDXTgBqky8/ay7Pbo4APAf+x1XcCNwK3AJvbNMDdwP9sAbQZ2FVVrwHPJplgECQAE1X1DECSXW3sScNjzZo17N+/f+Y9lCS9KcmP52M9s7rmkWRZkgPAUWAf8CPg5ap6vQ05BKxs0yuB5wHa/FeAdw7XT1hmurokaUTNKjyq6o2q2gCsYvBp4ddPa1fTSLItyf4k+48dO7YYLUiS6LzbqqpeBu4DfhtYnmTytNcq4HCbPgysBmjzfxV4cbh+wjLT1afa/q1VNV5V42Njcz5lJ0k6RbO522osyfI2/VYGF7afZBAiV7ZhW4F72vTu9po2/zvtusluYEu7G2stsA54kMEF8nXt7q1zgC1trCRpRM14wRy4ENiZZBmDsLmrqv4qyRPAriSfBX4A3NbG3wb8RbsgfpxBGFBVB5PcxeBC+OvAtVX1BkCS64C9wDJgR1UdnLc9lCTNuxlv1R1V4+Pj5d1WktQnycNVNT7X9fgNc0lSN8NDktTN8JAkdZvNBfN/dtZs/+tF2e5zn/v9RdmuJM03P3lIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuhockqduM4ZFkdZL7kjyR5GCST7T6jUkOJznQHpcPLXN9kokkTyW5dKi+qdUmkmwfqq9N8kCr35nknPneUUnS/JnNJ4/XgT+uqvXAJcC1Sda3eV+qqg3tsQegzdsC/AawCfjzJMuSLAO+DFwGrAeuGlrP59u6fg14CbhmnvZPknQazBgeVXWkqr7fpn8KPAmsPMkim4FdVfVaVT0LTAAXt8dEVT1TVb8AdgGbkwT4EHB3W34ncMWp7pAk6fTruuaRZA3wPuCBVrouyaNJdiRZ0WorgeeHFjvUatPV3wm8XFWvn1CXJI2oWYdHkrcD3wA+WVWvArcA7wE2AEeAL5yWDv9xD9uS7E+y/9ixY6d7c5KkacwqPJKczSA4vlZV3wSoqheq6o2q+gfgqwxOSwEcBlYPLb6q1aarvwgsT3LWCfV/oqpurarxqhofGxubTeuSpNNgNndbBbgNeLKqvjhUv3Bo2EeAx9v0bmBLknOTrAXWAQ8CDwHr2p1V5zC4qL67qgq4D7iyLb8VuGduuyVJOp3OmnkIvwP8AfBYkgOt9icM7pbaABTwHPBHAFV1MMldwBMM7tS6tqreAEhyHbAXWAbsqKqDbX2fAnYl+SzwAwZhJUkaUTOGR1V9D8gUs/acZJmbgJumqO+ZarmqeoZfnvaSJI04v2EuSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuM4ZHktVJ7kvyRJKDST7R6ucl2Zfk6fa8otWT5OYkE0keTXLR0Lq2tvFPJ9k6VP+tJI+1ZW5OktOxs5Kk+TGbTx6vA39cVeuBS4Brk6wHtgP3VtU64N72GuAyYF17bANugUHYADcA7wcuBm6YDJw25g+Hlts0912TJJ0uM4ZHVR2pqu+36Z8CTwIrgc3AzjZsJ3BFm94M3FED9wPLk1wIXArsq6rjVfUSsA/Y1Ob9SlXdX1UF3DG0LknSCOq65pFkDfA+4AHggqo60mb9BLigTa8Enh9a7FCrnax+aIr6VNvflmR/kv3Hjh3raV2SNI9mHR5J3g58A/hkVb06PK99Yqh57u2fqKpbq2q8qsbHxsZO9+YkSdOYVXgkOZtBcHytqr7Zyi+0U06056OtfhhYPbT4qlY7WX3VFHVJ0oiazd1WAW4DnqyqLw7N2g1M3jG1FbhnqH51u+vqEuCVdnprL7AxyYp2oXwjsLfNezXJJW1bVw+tS5I0gs6axZjfAf4AeCzJgVb7E+BzwF1JrgF+DHy0zdsDXA5MAD8HPgZQVceTfAZ4qI37dFUdb9MfB24H3gp8uz0kSSNqxvCoqu8B033v4sNTjC/g2mnWtQPYMUV9P/DemXqRJI0Gv2EuSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuM4ZHkh1JjiZ5fKh2Y5LDSQ60x+VD865PMpHkqSSXDtU3tdpEku1D9bVJHmj1O5OcM587KEmaf7P55HE7sGmK+peqakN77AFIsh7YAvxGW+bPkyxLsgz4MnAZsB64qo0F+Hxb168BLwHXzGWHJEmn34zhUVXfBY7Pcn2bgV1V9VpVPQtMABe3x0RVPVNVvwB2AZuTBPgQcHdbfidwRec+SJIW2FyueVyX5NF2WmtFq60Enh8ac6jVpqu/E3i5ql4/oT6lJNuS7E+y/9ixY3NoXZI0F6caHrcA7wE2AEeAL8xbRydRVbdW1XhVjY+NjS3EJiVJUzjrVBaqqhcmp5N8Ffir9vIwsHpo6KpWY5r6i8DyJGe1Tx/D4yVJI+qUPnkkuXDo5UeAyTuxdgNbkpybZC2wDngQeAhY1+6sOofBRfXdVVXAfcCVbfmtwD2n0pMkaeHM+MkjydeBDwLnJzkE3AB8MMkGoIDngD8CqKqDSe4CngBeB66tqjfaeq4D9gLLgB1VdbBt4lPAriSfBX4A3DZveydJOi1mDI+qumqK8rT/wFfVTcBNU9T3AHumqD/D4G4sSdIS4TfMJUndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUbcbwSLIjydEkjw/VzkuyL8nT7XlFqyfJzUkmkjya5KKhZba28U8n2TpU/60kj7Vlbk6S+d5JSdL8ms0nj9uBTSfUtgP3VtU64N72GuAyYF17bANugUHYADcA7wcuBm6YDJw25g+HljtxW5KkETNjeFTVd4HjJ5Q3Azvb9E7giqH6HTVwP7A8yYXApcC+qjpeVS8B+4BNbd6vVNX9VVXAHUPrkiSNqFO95nFBVR1p0z8BLmjTK4Hnh8YdarWT1Q9NUZ9Skm1J9ifZf+zYsVNsXZI0V3O+YN4+MdQ89DKbbd1aVeNVNT42NrYQm5QkTeFUw+OFdsqJ9ny01Q8Dq4fGrWq1k9VXTVGXJI2wUw2P3cDkHVNbgXuG6le3u64uAV5pp7f2AhuTrGgXyjcCe9u8V5Nc0u6yunpoXZKkEXXWTAOSfB34IHB+kkMM7pr6HHBXkmuAHwMfbcP3AJcDE8DPgY8BVNXxJJ8BHmrjPl1VkxfhP87gjq63At9uD0nSCJsxPKrqqmlmfXiKsQVcO816dgA7pqjvB947Ux+SpNHhN8wlSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lStzmFR5LnkjyW5ECS/a12XpJ9SZ5uzytaPUluTjKR5NEkFw2tZ2sb/3SSrXPbJUnS6TYfnzz+fVVtqKrx9no7cG9VrQPuba8BLgPWtcc24BYYhA1wA/B+4GLghsnAkSSNptNx2mozsLNN7wSuGKrfUQP3A8uTXAhcCuyrquNV9RKwD9h0GvqSJM2TuYZHAX+T5OEk21rtgqo60qZ/AlzQplcCzw8te6jVpqtLkkbUWXNc/gNVdTjJvwT2Jfm74ZlVVUlqjtt4UwuobQDvete75mu1kqROc/rkUVWH2/NR4FsMrlm80E5H0Z6PtuGHgdVDi69qtenqU23v1qoar6rxsbGxubQuSZqDUw6PJG9L8o7JaWAj8DiwG5i8Y2orcE+b3g1c3e66ugR4pZ3e2gtsTLKiXSjf2GqSpBE1l9NWFwDfSjK5nv9dVf83yUPAXUmuAX4MfLSN3wNcDkwAPwc+BlBVx5N8Bniojft0VR2fQ1+SpNPslMOjqp4B/u0U9ReBD09RL+Daada1A9hxqr1IkhaW3zCXJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVK3kQmPJJuSPJVkIsn2xe5HkjS9kQiPJMuALwOXAeuBq5KsX9yuJEnTGYnwAC4GJqrqmar6BbAL2LzIPUmSpnHWYjfQrASeH3p9CHj/IvVy2qzZ/teLtu3nPvf7i7ZtSf/8jEp4zEqSbcC29vJnSZ46xVWdD/z9/HS1YObUcz4/j530WYrHGpZm30uxZ1iafS/FnmHQ97+ejxWNSngcBlYPvV7Vav9IVd0K3DrXjSXZX1Xjc13PQlqKPYN9L6Sl2DMszb6XYs/wZt9r5mNdo3LN4yFgXZK1Sc4BtgC7F7knSdI0RuKTR1W9nuQ6YC+wDNhRVQcXuS1J0jRGIjwAqmoPsGeBNjfnU1+LYCn2DPa9kJZiz7A0+16KPcM89p2qmq91SZLOEKNyzUOStIScUeEx6j+BkuS5JI8lOZBkf6udl2Rfkqfb84pWT5Kb2748muSiBexzR5KjSR4fqnX3mWRrG/90kq2L0PONSQ63430gyeVD865vPT+V5NKh+oK9h5KsTnJfkieSHEzyiVYf9WM9Xd+jfrzfkuTBJI+0vv+s1dcmeaD1cGe7qYck57bXE23+mpn2ZwF7vj3Js0PHekOrz997pKrOiAeDC/E/At4NnAM8Aqxf7L5O6PE54PwTav8D2N6mtwOfb9OXA98GAlwCPLCAff4ucBHw+Kn2CZwHPNOeV7TpFQvc843Af5ti7Pr2/jgXWNveN8sW+j0EXAhc1KbfAfyw9Tbqx3q6vkf9eAd4e5s+G3igHce7gC2t/hXgv7TpjwNfadNbgDtPtj8L3PPtwJVTjJ+398iZ9Mljqf4EymZgZ5veCVwxVL+jBu4Hlie5cCEaqqrvAsfn2OelwL6qOl5VLwH7gE0L3PN0NgO7quq1qnoWmGDw/lnQ91BVHamq77fpnwJPMvg1hlE/1tP1PZ1ROd5VVT9rL89ujwI+BNzd6ice78k/h7uBDyfJSfZnIXuezry9R86k8JjqJ1BO9oZeDAX8TZKHM/g2PcAFVXWkTf8EuKBNj9r+9PY5Kv1f1z6+75g8/cMI9txOibyPwf8sl8yxPqFvGPHjnWRZkgPAUQb/gP4IeLmqXp+ihzf7a/NfAd650H2f2HNVTR7rm9qx/lKSc0/s+YTeuns+k8JjKfhAVV3E4NeFr03yu8Mza/D5cuRvj1sqfQK3AO8BNgBHgC8sbjtTS/J24BvAJ6vq1eF5o3ysp+h75I93Vb1RVRsY/MrFxcCvL3JLMzqx5yTvBa5n0Pu/Y3Aq6lPzvd0zKTxm9RMoi6mqDrfno8C3GLx5X5g8HdWej7bho7Y/vX0uev9V9UL7i/cPwFf55amFkek5ydkM/gH+WlV9s5VH/lhP1fdSON6Tqupl4D7gtxmc2pn8TtxwD2/21+b/KvAii9T3UM+b2qnDqqrXgP/FaTjWZ1J4jPRPoCR5W5J3TE4DG4HHGfQ4eefDVuCeNr0buLrdPXEJ8MrQqYzF0NvnXmBjkhXt9MXGVlswJ1wj+giD4z3Z85Z2N81aYB3wIAv8Hmrnz28DnqyqLw7NGuljPV3fS+B4jyVZ3qbfCvweg+s19wFXtmEnHu/JP4crge+0T4LT7c9C9fx3Q/+5CINrNMPHen7eI6d6lX8pPhjcafBDBucx/3Sx+zmht3czuEPjEeDgZH8MzqHeCzwN/C1wXv3yLosvt315DBhfwF6/zuC0w/9jcG70mlPpE/hPDC4mTgAfW4Se/6L19Gj7S3Xh0Pg/bT0/BVy2GO8h4AMMTkk9Chxoj8uXwLGeru9RP96/Cfyg9fc48N9b/d0M/vGfAP4PcG6rv6W9nmjz3z3T/ixgz99px/px4C/55R1Z8/Ye8RvmkqRuZ9JpK0nSPDE8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1O3/A1GXUoyP3SVxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TLcFbCnQpxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25ff2c2d-ecf0-4cdb-c254-89cde7b8aec1"
      },
      "source": [
        "# 정수 인코딩\n",
        "tokenizer = Tokenizer(num_words=7000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "print('# int_encoding done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# int_encoding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgVP6bQMQp1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef069894-cb9a-4689-d2c4-e6e5371127ac"
      },
      "source": [
        "# padding\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=30)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=30)\n",
        "print('# padding done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# padding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSoE1BKdOoYw",
        "colab_type": "text"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBd-kxcQY54P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea33a7c7-f2a8-4854-f355-8a5ee0867bb2"
      },
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31947, 30) (7987, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4dHKFvw_y8U",
        "colab_type": "text"
      },
      "source": [
        "#### - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNrCYJNiOoct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "\n",
        "# model.add(Embedding(7000, 256, input_length=len(X_train[0])))\n",
        "# model.add(LSTM(256))\n",
        "# model.add(Dense(y_train.shape[1], activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2YEUQMy_Weg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
        "# # overfitting 조짐이 보여서 lstm layer 수 변경\n",
        "# # 128 -> 32 -> 256 : 32가 제일 낫긴 한데 구리긴 마찬가지(val_acc : 0.3대가 제일 높음)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLd4FR60lTCT",
        "colab_type": "text"
      },
      "source": [
        "#### - CNN(LSTM의 성능이 나빠서 solution 참고하여 CNN 사용 → 성능은 LSTM과 비슷하게 좋지 않음)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM4iUiB-_9MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 함수형 케라스\n",
        "inputs = Input(shape=(30,))\n",
        "embed = Embedding(7000, 30)(inputs)\n",
        "drop = Dropout(0.3)(embed)\n",
        "\n",
        "\n",
        "# 모델 합성\n",
        "concat_layers = []\n",
        "\n",
        "conv = Conv1D(30 , 3, padding='same', activation='relu')(drop)\n",
        "pool = GlobalMaxPooling1D()(conv)\n",
        "flat = Flatten()(pool)\n",
        "concat_layers.append(flat)\n",
        "\n",
        "conv = Conv1D(30, 4, padding='same', activation='relu')(drop)\n",
        "pool = GlobalMaxPooling1D()(conv)\n",
        "flat = Flatten()(pool)\n",
        "concat_layers.append(flat)\n",
        "\n",
        "conv = Conv1D(30, 5, padding='same', activation='relu')(drop)\n",
        "pool = GlobalMaxPooling1D()(conv)\n",
        "flat = Flatten()(pool)\n",
        "concat_layers.append(flat)\n",
        "\n",
        "concat = Concatenate()(concat_layers)\n",
        "relu = Dense(64, activation='relu')(concat)\n",
        "drop = Dropout(0.5)(relu)\n",
        "\n",
        "outputs = Dense(y_train[0].shape[0], activation='softmax')(drop)\n",
        "\n",
        "model = Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWPh3QSrFyva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9bdf074-2aeb-4ce5-e779-4aac7eb08703"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 2.1803 - accuracy: 0.2361 - val_loss: 2.0924 - val_accuracy: 0.2707\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 2.0212 - accuracy: 0.3082 - val_loss: 1.9732 - val_accuracy: 0.3268\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.9476 - accuracy: 0.3427 - val_loss: 1.9303 - val_accuracy: 0.3411\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.9057 - accuracy: 0.3555 - val_loss: 1.9061 - val_accuracy: 0.3523\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.8729 - accuracy: 0.3702 - val_loss: 1.8970 - val_accuracy: 0.3528\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.8499 - accuracy: 0.3804 - val_loss: 1.9038 - val_accuracy: 0.3489\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.8279 - accuracy: 0.3881 - val_loss: 1.9024 - val_accuracy: 0.3524\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.8099 - accuracy: 0.3938 - val_loss: 1.9099 - val_accuracy: 0.3529\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7931 - accuracy: 0.4005 - val_loss: 1.9089 - val_accuracy: 0.3547\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7761 - accuracy: 0.4066 - val_loss: 1.9157 - val_accuracy: 0.3532\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7542 - accuracy: 0.4123 - val_loss: 1.9282 - val_accuracy: 0.3533\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7441 - accuracy: 0.4178 - val_loss: 1.9306 - val_accuracy: 0.3501\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7247 - accuracy: 0.4262 - val_loss: 1.9436 - val_accuracy: 0.3479\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7123 - accuracy: 0.4278 - val_loss: 1.9633 - val_accuracy: 0.3472\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7009 - accuracy: 0.4330 - val_loss: 1.9572 - val_accuracy: 0.3463\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6813 - accuracy: 0.4441 - val_loss: 1.9865 - val_accuracy: 0.3438\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6715 - accuracy: 0.4440 - val_loss: 1.9880 - val_accuracy: 0.3476\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6637 - accuracy: 0.4470 - val_loss: 1.9885 - val_accuracy: 0.3452\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6523 - accuracy: 0.4530 - val_loss: 2.0037 - val_accuracy: 0.3471\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6375 - accuracy: 0.4544 - val_loss: 2.0180 - val_accuracy: 0.3427\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6317 - accuracy: 0.4597 - val_loss: 2.0238 - val_accuracy: 0.3443\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6232 - accuracy: 0.4618 - val_loss: 2.0547 - val_accuracy: 0.3393\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6143 - accuracy: 0.4662 - val_loss: 2.0424 - val_accuracy: 0.3427\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.6089 - accuracy: 0.4726 - val_loss: 2.0556 - val_accuracy: 0.3412\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5970 - accuracy: 0.4735 - val_loss: 2.0667 - val_accuracy: 0.3414\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5947 - accuracy: 0.4765 - val_loss: 2.0629 - val_accuracy: 0.3389\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5851 - accuracy: 0.4783 - val_loss: 2.0900 - val_accuracy: 0.3423\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 1.5799 - accuracy: 0.4808 - val_loss: 2.1178 - val_accuracy: 0.3380\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 1.5705 - accuracy: 0.4856 - val_loss: 2.1024 - val_accuracy: 0.3392\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 1.5579 - accuracy: 0.4871 - val_loss: 2.1127 - val_accuracy: 0.3419\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5603 - accuracy: 0.4875 - val_loss: 2.1115 - val_accuracy: 0.3363\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5496 - accuracy: 0.4890 - val_loss: 2.1632 - val_accuracy: 0.3345\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5461 - accuracy: 0.4908 - val_loss: 2.1190 - val_accuracy: 0.3379\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5424 - accuracy: 0.4970 - val_loss: 2.1713 - val_accuracy: 0.3357\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5437 - accuracy: 0.4959 - val_loss: 2.1727 - val_accuracy: 0.3412\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5293 - accuracy: 0.5007 - val_loss: 2.1845 - val_accuracy: 0.3378\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5329 - accuracy: 0.5028 - val_loss: 2.1423 - val_accuracy: 0.3343\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5268 - accuracy: 0.5007 - val_loss: 2.1855 - val_accuracy: 0.3403\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5259 - accuracy: 0.5087 - val_loss: 2.2244 - val_accuracy: 0.3377\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5248 - accuracy: 0.5025 - val_loss: 2.2349 - val_accuracy: 0.3354\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5119 - accuracy: 0.5066 - val_loss: 2.2038 - val_accuracy: 0.3357\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5091 - accuracy: 0.5079 - val_loss: 2.1921 - val_accuracy: 0.3358\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5062 - accuracy: 0.5113 - val_loss: 2.1499 - val_accuracy: 0.3328\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5033 - accuracy: 0.5104 - val_loss: 2.2358 - val_accuracy: 0.3364\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5085 - accuracy: 0.5093 - val_loss: 2.2802 - val_accuracy: 0.3391\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5096 - accuracy: 0.5074 - val_loss: 2.2539 - val_accuracy: 0.3345\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5010 - accuracy: 0.5118 - val_loss: 2.2398 - val_accuracy: 0.3334\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4935 - accuracy: 0.5133 - val_loss: 2.2556 - val_accuracy: 0.3292\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5009 - accuracy: 0.5103 - val_loss: 2.2458 - val_accuracy: 0.3322\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4996 - accuracy: 0.5131 - val_loss: 2.2546 - val_accuracy: 0.3319\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4995 - accuracy: 0.5120 - val_loss: 2.2854 - val_accuracy: 0.3323\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4989 - accuracy: 0.5112 - val_loss: 2.2654 - val_accuracy: 0.3339\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5030 - accuracy: 0.5145 - val_loss: 2.2143 - val_accuracy: 0.3319\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4957 - accuracy: 0.5141 - val_loss: 2.2780 - val_accuracy: 0.3347\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4955 - accuracy: 0.5119 - val_loss: 2.3023 - val_accuracy: 0.3328\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4884 - accuracy: 0.5179 - val_loss: 2.2763 - val_accuracy: 0.3302\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4927 - accuracy: 0.5176 - val_loss: 2.3126 - val_accuracy: 0.3317\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4954 - accuracy: 0.5149 - val_loss: 2.2408 - val_accuracy: 0.3305\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4931 - accuracy: 0.5149 - val_loss: 2.2932 - val_accuracy: 0.3365\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4920 - accuracy: 0.5195 - val_loss: 2.2898 - val_accuracy: 0.3305\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4947 - accuracy: 0.5160 - val_loss: 2.2242 - val_accuracy: 0.3288\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4959 - accuracy: 0.5172 - val_loss: 2.2690 - val_accuracy: 0.3345\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4997 - accuracy: 0.5149 - val_loss: 2.2694 - val_accuracy: 0.3312\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4892 - accuracy: 0.5161 - val_loss: 2.3153 - val_accuracy: 0.3294\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.4970 - accuracy: 0.5134 - val_loss: 2.3038 - val_accuracy: 0.3315\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4986 - accuracy: 0.5147 - val_loss: 2.3075 - val_accuracy: 0.3303\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4971 - accuracy: 0.5165 - val_loss: 2.3015 - val_accuracy: 0.3285\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4997 - accuracy: 0.5167 - val_loss: 2.3075 - val_accuracy: 0.3303\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.4976 - accuracy: 0.5114 - val_loss: 2.3115 - val_accuracy: 0.3255\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5090 - accuracy: 0.5160 - val_loss: 2.3220 - val_accuracy: 0.3299\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5058 - accuracy: 0.5116 - val_loss: 2.3056 - val_accuracy: 0.3307\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5073 - accuracy: 0.5127 - val_loss: 2.3893 - val_accuracy: 0.3299\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5027 - accuracy: 0.5155 - val_loss: 2.3080 - val_accuracy: 0.3290\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5055 - accuracy: 0.5165 - val_loss: 2.3057 - val_accuracy: 0.3252\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5091 - accuracy: 0.5128 - val_loss: 2.3490 - val_accuracy: 0.3295\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5034 - accuracy: 0.5154 - val_loss: 2.3502 - val_accuracy: 0.3258\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5185 - accuracy: 0.5139 - val_loss: 2.2317 - val_accuracy: 0.3268\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5139 - accuracy: 0.5120 - val_loss: 2.3416 - val_accuracy: 0.3240\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5231 - accuracy: 0.5096 - val_loss: 2.2907 - val_accuracy: 0.3290\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5200 - accuracy: 0.5105 - val_loss: 2.3255 - val_accuracy: 0.3282\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5146 - accuracy: 0.5095 - val_loss: 2.2486 - val_accuracy: 0.3307\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5184 - accuracy: 0.5087 - val_loss: 2.3549 - val_accuracy: 0.3304\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5165 - accuracy: 0.5091 - val_loss: 2.4181 - val_accuracy: 0.3334\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5223 - accuracy: 0.5096 - val_loss: 2.3143 - val_accuracy: 0.3277\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5276 - accuracy: 0.5068 - val_loss: 2.3529 - val_accuracy: 0.3328\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5266 - accuracy: 0.5063 - val_loss: 2.3187 - val_accuracy: 0.3289\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5269 - accuracy: 0.5115 - val_loss: 2.3622 - val_accuracy: 0.3285\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5403 - accuracy: 0.5069 - val_loss: 2.3354 - val_accuracy: 0.3278\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5300 - accuracy: 0.5113 - val_loss: 2.2777 - val_accuracy: 0.3194\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5439 - accuracy: 0.5040 - val_loss: 2.2786 - val_accuracy: 0.3219\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5386 - accuracy: 0.5083 - val_loss: 2.3205 - val_accuracy: 0.3272\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5406 - accuracy: 0.5025 - val_loss: 2.3836 - val_accuracy: 0.3303\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5434 - accuracy: 0.5047 - val_loss: 2.3365 - val_accuracy: 0.3243\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5399 - accuracy: 0.5048 - val_loss: 2.2848 - val_accuracy: 0.3210\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.5539 - accuracy: 0.5015 - val_loss: 2.3369 - val_accuracy: 0.3257\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5479 - accuracy: 0.5017 - val_loss: 2.3240 - val_accuracy: 0.3199\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5477 - accuracy: 0.5022 - val_loss: 2.3377 - val_accuracy: 0.3300\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5487 - accuracy: 0.4990 - val_loss: 2.3237 - val_accuracy: 0.3206\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5632 - accuracy: 0.4995 - val_loss: 2.3135 - val_accuracy: 0.3221\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.5585 - accuracy: 0.5031 - val_loss: 2.2728 - val_accuracy: 0.3280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faf78754400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CXLZTLwG3yP",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# 모델 수정해서 성능 높이기\n",
        "\n",
        "- nltk를 이용해서 토큰화하기\n",
        "- 그동안 배운 RNN, LSTM, CNN을 이용하여 레이어를 다양하게 쌓아보기\n",
        "- 하이퍼파라미터 다양하게 바꿔보기\n",
        "- 앙상블하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A-2o6LZdB3W",
        "colab_type": "text"
      },
      "source": [
        "## 1. SimpleRNN \n",
        "- loss: 1.8556 - accuracy: 0.3823 - val_loss: 2.1245 - val_accuracy: 0.2719"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KwPLdgId9Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import SimpleRNN\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "Inputs = Input(shape=(30,))\n",
        "embed = Embedding(vocab_size, 50)(Inputs)\n",
        "rnn_outputs = SimpleRNN(50)(embed) # 50 = dimensionality of the output space\n",
        "Outputs = Dense(y_train[0].shape[0], activation='softmax')(rnn_outputs)\n",
        "\n",
        "mod_rnn = Model(Inputs, Outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue4Qi4Vc39bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "480dde81-f62f-4475-ecc4-96f7c7e8ad9f"
      },
      "source": [
        "mod_rnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "mod_rnn.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 15s 30ms/step - loss: 2.1118 - accuracy: 0.2537 - val_loss: 2.1045 - val_accuracy: 0.2661\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 15s 30ms/step - loss: 1.9870 - accuracy: 0.3215 - val_loss: 2.1580 - val_accuracy: 0.2517\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 15s 30ms/step - loss: 1.8556 - accuracy: 0.3823 - val_loss: 2.1245 - val_accuracy: 0.2719\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 15s 29ms/step - loss: 1.7304 - accuracy: 0.4312 - val_loss: 2.2374 - val_accuracy: 0.2499\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 1.6139 - accuracy: 0.4750 - val_loss: 2.3350 - val_accuracy: 0.2514\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 1.5032 - accuracy: 0.5176 - val_loss: 2.3210 - val_accuracy: 0.2583\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 15s 29ms/step - loss: 1.4034 - accuracy: 0.5567 - val_loss: 2.5739 - val_accuracy: 0.2296\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 15s 29ms/step - loss: 1.3114 - accuracy: 0.5895 - val_loss: 2.5985 - val_accuracy: 0.2399\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 1.2250 - accuracy: 0.6182 - val_loss: 2.7378 - val_accuracy: 0.2339\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 1.1506 - accuracy: 0.6464 - val_loss: 2.8118 - val_accuracy: 0.2091\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 1.0833 - accuracy: 0.6706 - val_loss: 2.6953 - val_accuracy: 0.2400\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 1.0183 - accuracy: 0.6898 - val_loss: 2.9115 - val_accuracy: 0.2182\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 0.9586 - accuracy: 0.7101 - val_loss: 3.1034 - val_accuracy: 0.2235\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 0.9089 - accuracy: 0.7256 - val_loss: 3.0602 - val_accuracy: 0.2108\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.8605 - accuracy: 0.7412 - val_loss: 3.2097 - val_accuracy: 0.2115\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.8156 - accuracy: 0.7584 - val_loss: 3.1492 - val_accuracy: 0.2152\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.7748 - accuracy: 0.7668 - val_loss: 3.4281 - val_accuracy: 0.2051\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.7400 - accuracy: 0.7812 - val_loss: 3.3435 - val_accuracy: 0.2122\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.7039 - accuracy: 0.7895 - val_loss: 3.2922 - val_accuracy: 0.2186\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6763 - accuracy: 0.7993 - val_loss: 3.4554 - val_accuracy: 0.2107\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6429 - accuracy: 0.8102 - val_loss: 3.4711 - val_accuracy: 0.2078\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6187 - accuracy: 0.8182 - val_loss: 3.5748 - val_accuracy: 0.1927\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.5949 - accuracy: 0.8232 - val_loss: 3.6733 - val_accuracy: 0.1947\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 0.5707 - accuracy: 0.8300 - val_loss: 3.6180 - val_accuracy: 0.2086\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5509 - accuracy: 0.8369 - val_loss: 3.6264 - val_accuracy: 0.2110\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5277 - accuracy: 0.8433 - val_loss: 3.8411 - val_accuracy: 0.2006\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5125 - accuracy: 0.8475 - val_loss: 3.9291 - val_accuracy: 0.2043\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4937 - accuracy: 0.8545 - val_loss: 3.7280 - val_accuracy: 0.2060\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4741 - accuracy: 0.8587 - val_loss: 3.8416 - val_accuracy: 0.2030\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4655 - accuracy: 0.8640 - val_loss: 3.9121 - val_accuracy: 0.1976\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4513 - accuracy: 0.8661 - val_loss: 3.8747 - val_accuracy: 0.2122\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.4359 - accuracy: 0.8719 - val_loss: 3.8750 - val_accuracy: 0.2137\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4264 - accuracy: 0.8748 - val_loss: 4.0162 - val_accuracy: 0.2087\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.4163 - accuracy: 0.8773 - val_loss: 4.1398 - val_accuracy: 0.2055\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4038 - accuracy: 0.8790 - val_loss: 3.9611 - val_accuracy: 0.2068\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.3941 - accuracy: 0.8841 - val_loss: 4.3998 - val_accuracy: 0.1778\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.3857 - accuracy: 0.8850 - val_loss: 4.1824 - val_accuracy: 0.2027\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3720 - accuracy: 0.8901 - val_loss: 4.2998 - val_accuracy: 0.1992\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3684 - accuracy: 0.8894 - val_loss: 4.2580 - val_accuracy: 0.1981\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3600 - accuracy: 0.8925 - val_loss: 4.1182 - val_accuracy: 0.2146\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3553 - accuracy: 0.8949 - val_loss: 4.3443 - val_accuracy: 0.1903\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3455 - accuracy: 0.8965 - val_loss: 4.4196 - val_accuracy: 0.1957\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3354 - accuracy: 0.9000 - val_loss: 4.5194 - val_accuracy: 0.1858\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3355 - accuracy: 0.9000 - val_loss: 4.3748 - val_accuracy: 0.1979\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3258 - accuracy: 0.9023 - val_loss: 4.4027 - val_accuracy: 0.2106\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.3199 - accuracy: 0.9043 - val_loss: 4.4877 - val_accuracy: 0.1986\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.3138 - accuracy: 0.9072 - val_loss: 4.4769 - val_accuracy: 0.2032\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.3089 - accuracy: 0.9064 - val_loss: 4.4069 - val_accuracy: 0.1988\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.3048 - accuracy: 0.9091 - val_loss: 4.6075 - val_accuracy: 0.2001\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.2963 - accuracy: 0.9121 - val_loss: 4.3216 - val_accuracy: 0.2052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2d49e39470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3kGJlCYORjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc5o7wYSOotq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WCL42fAZ3zG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bfbe9e95-b3b2-4b07-d523-f7878705d165"
      },
      "source": [
        "stc = input() # 영어\n",
        "stc = stc.lower()\n",
        "\n",
        "import re\n",
        "stc = re.sub('[^\\w]', ' ', stc)\n",
        "token_stc = stc.split()\n",
        "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=32)\n",
        "\n",
        "score = model.predict(pad_stc)\n",
        "\n",
        "print(y_cate_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i know  i was listenin to bad habit earlier and i started freakin at his part\n",
            "worry 0.17115688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1FImaevRbH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}