{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   다시  날씨  좋네요  감사해요  안녕하세요  만나요  잘있어요  오늘  좋은  가  하루  도  보내세요\n",
      "0   1   0    0     1      1    1     1   0   0  0   0  0     0\n",
      "1   0   0    0     0      1    0     0   1   1  0   1  1     1\n",
      "2   0   1    1     0      3    0     0   1   0  1   0  1     0\n",
      "            idf\n",
      "다시     0.405465\n",
      "날씨     0.405465\n",
      "좋네요    0.405465\n",
      "감사해요   0.405465\n",
      "안녕하세요 -0.287682\n",
      "만나요    0.405465\n",
      "잘있어요   0.405465\n",
      "오늘     0.000000\n",
      "좋은     0.405465\n",
      "가      0.405465\n",
      "하루     0.405465\n",
      "도      0.000000\n",
      "보내세요   0.405465\n",
      "         다시        날씨       좋네요      감사해요     안녕하세요       만나요      잘있어요   오늘  \\\n",
      "0  0.405465  0.000000  0.000000  0.405465 -0.287682  0.405465  0.405465  0.0   \n",
      "1  0.000000  0.000000  0.000000  0.000000 -0.287682  0.000000  0.000000  0.0   \n",
      "2  0.000000  0.405465  0.405465  0.000000 -0.863046  0.000000  0.000000  0.0   \n",
      "\n",
      "         좋은         가        하루    도      보내세요  \n",
      "0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
      "1  0.405465  0.000000  0.405465  0.0  0.405465  \n",
      "2  0.000000  0.405465  0.000000  0.0  0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "doc_list = [\n",
    "    '안녕하세요 감사해요 잘있어요 다시 만나요',\n",
    "    '안녕하세요 오늘도 좋은 하루 보내세요',\n",
    "    '안녕하세요 안녕하세요 안녕하세요 오늘도 날씨가 좋네요',\n",
    "]\n",
    "\n",
    "# 문서 전체의 단어들을 토큰화\n",
    "token_list = Okt().morphs(' '.join(doc_list))\n",
    "# 중복 단어를 제거하고 unique한 단어만 추출\n",
    "token_list = list(set(token_list))\n",
    "\n",
    "\n",
    "def tf(term, document):\n",
    "    return document.count(term) # ★★★\n",
    "\n",
    "def idf(term):\n",
    "    df = 0\n",
    "    for doc in doc_list:\n",
    "        if term in doc:\n",
    "            df += 1\n",
    "    return log(len(doc_list)/(df+1)) \n",
    "\n",
    "def tfidf(term, document):\n",
    "    return tf(term, document) * idf(term) # ★★★한 번에 쓰기★★★\n",
    "\n",
    "dtm = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # ★★★새로운 list append하는 방법★★★ ----------------\n",
    "    dtm.append([])   \n",
    "    for token in token_list:\n",
    "        dtm[-1].append(tf(token, doc))\n",
    "    #---------------------------------------------------------\n",
    "    \n",
    "dtm_pd = pd.DataFrame(dtm, columns=token_list)\n",
    "print(dtm_pd)\n",
    "\n",
    "idf_list = []\n",
    "\n",
    "for token in token_list:\n",
    "    idf_list.append(idf(token))\n",
    "\n",
    "idf_pd = pd.DataFrame(idf_list, columns=['idf'], index=token_list)\n",
    "print(idf_pd)\n",
    "\n",
    "tfidf_list = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    tfidf_list.append([])\n",
    "    for token in token_list:\n",
    "        tfidf_list[-1].append(tfidf(token, doc))\n",
    "    \n",
    "\n",
    "tfidf_pd = pd.DataFrame(tfidf_list, columns=token_list)\n",
    "print(tfidf_pd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
