{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from math import log, exp   # 기본 자연로그\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_csv():\n",
    "    f = open('./data/IMDB Dataset.csv', 'r', encoding='utf-8')\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    pos_doc = []\n",
    "    neg_doc = []\n",
    "    \n",
    "    next(csvreader) # header 제외\n",
    "    for line in csvreader:\n",
    "        if line[1] == 'positive':\n",
    "            pos_doc.append(line[0]) # 그냥 line으로 쓰면 list로 들어가게 됨\n",
    "        else:\n",
    "            neg_doc.append(line[0])\n",
    "    \n",
    "    train_datas = [[], []]\n",
    "    train_datas[0] = neg_doc\n",
    "    train_datas[1] = pos_doc\n",
    "    \n",
    "    # train data의 0번째 인덱스와 1번째 인덱스 문자열\n",
    "    # 리스트는 토큰화가 어려워서 전부 조인을 통해서 하나의 문자열로 바꾼다.\n",
    "    return [' '.join(train_datas[0]), ' '.join(train_datas[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data가 긍정이면, P(test_data|긍정)\n",
    "# train_data가 부정이면, P(test_data|부정)\n",
    "# 만약 train_data에 테스트할 단어가 없으면, 확률을 알 수 없음 -> nowords_weight(하이퍼파라미터)\n",
    "def calculate_doc_prob(train_data, test_data, nowords_weight):\n",
    "    log_prob = 0 # 확률을 곱하는 것은 log 확률을 더하는 것과 같다\n",
    "                 # 확률이 0에 수렴하지 않게 log 확률을 사용\n",
    "        \n",
    "    # train------------------------------------------------------\n",
    "    # stopwords 제거\n",
    "    sw_train_data = re.compile(\"[^\\w]\").sub(' ', train_data.lower())\n",
    "    # 토큰화\n",
    "    sw_train_token = sw_train_data.split() # 빠르게 단어 별로 tokenize\n",
    "    # Bow\n",
    "    train_vector = dict(Counter(sw_train_token)) # Counter를 쓰면 dict처럼 보이지만 Counter 객체로 나옴\n",
    "    \n",
    "    # test-------------------------------------------------------\n",
    "    # stopwords 제거\n",
    "    sw_test_data = re.compile(\"[^\\w]\").sub(' ', test_data.lower())\n",
    "    # 토큰화\n",
    "    sw_test_token = sw_test_data.split()\n",
    "    # Bow\n",
    "    test_vector = dict(Counter(sw_test_token)) \n",
    "    \n",
    "    # 전체 단어의 갯수\n",
    "    total_wc = len(sw_train_token)\n",
    "    \n",
    "    # log(P(test|긍정))\n",
    "    # test 문장에 있는 단어 별로 긍정인 문장에서 등장한 확률을 다 곱해준다.\n",
    "    # <=> log 확률을 다 더해준다\n",
    "    for word in test_vector:\n",
    "        if word in train_vector:\n",
    "            # P(단어|긍정)\n",
    "            log_prob += log(train_vector[word]/total_wc)\n",
    "        else:\n",
    "            log_prob += log(nowords_weight/total_wc) # nowords_weight는 주로 (0, 1) 값을 대입 \n",
    "                                                     # 1번 등장한 단어보다 비중을 줄여주기 위함\n",
    "                                                     # 강사님은 0.1 사용\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(train_datas, test_data, pos_prob, neg_prob):\n",
    "    # P(긍정|test) = P(test|긍정) * P(긍정) / P(test)\n",
    "    # P(test)로 나누는 부분은 중복되는 부분이므로 생략 \n",
    "    # 정확한 확률을 구하는 것이 목적이 아님\n",
    "    test_pos_prob = calculate_doc_prob(train_datas[1], test_data, 0.1) + log(pos_prob) \n",
    "    # P(부정|test) = P(test|부정) * P(부정) / P(test)\n",
    "    test_neg_prob = calculate_doc_prob(train_datas[0], test_data, 0.1) + log(neg_prob)\n",
    "    \n",
    "    # ------------정규화 작업\n",
    "    # 현재 구한 test_pos_prob, test_neg_prob은 절대값이 큰 음수라서 보기 쉽게 변환\n",
    "    # 긍정, 부정의 상대적 확률\n",
    "    # 긍정을 1로 놨을 때 부정의 확률 or 부정을 1로 놨을 때 긍정의 확률 \n",
    "    maxprob = max(test_neg_prob, test_pos_prob)\n",
    "    test_pos_prob -= maxprob\n",
    "    test_neg_prob -= maxprob\n",
    "    test_pos_prob = exp(test_pos_prob)\n",
    "    test_neg_prob = exp(test_neg_prob)\n",
    "    normalized_prob = [test_neg_prob/(test_neg_prob+test_pos_prob), test_pos_prob/(test_neg_prob+test_pos_prob)]\n",
    "    \n",
    "    return normalized_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    train_datas = open_csv() \n",
    "    \n",
    "    # 긍정 확률을 추정하고자 하는 새로운 문장\n",
    "    test_data = input()\n",
    "    # 위 두 데이터를 이용해서 확률을 계산\n",
    "    prob = naive_bayes(train_datas, test_data, 0.5, 0.5)\n",
    "    \n",
    "    print(f\"리뷰가 부정적인 확률 : {round(prob[0], 5)}, 긍정적일 확률 : {round(prob[1], 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original Score: 2.5/4 Despite all indicators pointing to romantic comedy, the film is devoid of romance. Slate leads an exceptional cast and there are funny moments but the film gets lost in translation from the novel.\n",
      "리뷰가 부정적인 확률 : 0.7928, 긍정적일 확률 : 0.2072\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# train, test를 분리해서 모델 평가하는 부분을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정 텍스트가 부정적일 확률 : 1.0, 긍정적인 확률 : 0.0\n",
      "긍정 텍스트가 부정적일 확률 : 0.0, 긍정적인 확률 : 1.0\n"
     ]
    }
   ],
   "source": [
    "def start_validate():\n",
    "    train_datas, test_data = open_csv_validate()\n",
    "    \n",
    "    prob_neg = naive_bayes(train_datas, test_data[0], 0.5, 0.5)\n",
    "    prob_pos = naive_bayes(train_datas, test_data[1], 0.5, 0.5)\n",
    "    \n",
    "    print(f\"부정 텍스트가 부정적일 확률 : {round(prob_neg[0], 5)}, 긍정적인 확률 : {round(prob_neg[1], 5)}\")\n",
    "    print(f\"긍정 텍스트가 부정적일 확률 : {round(prob_pos[0], 5)}, 긍정적인 확률 : {round(prob_pos[1], 5)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def open_csv_validate():\n",
    "    f = open('./data/IMDB Dataset.csv', 'r', encoding='utf-8')\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    pos_doc = []\n",
    "    neg_doc = []\n",
    "    \n",
    "    next(csvreader) \n",
    "    for line in csvreader:\n",
    "        if line[1] == 'positive':\n",
    "            pos_doc.append(line[0]) \n",
    "        else:\n",
    "            neg_doc.append(line[0])\n",
    "    \n",
    "    # 각 문서가 25000개 정도씩 있음(4:1로 분리)\n",
    "    train_datas = [[], []]\n",
    "    train_datas[0] = neg_doc[:20000]\n",
    "    train_datas[1] = pos_doc[:20000]\n",
    "    \n",
    "    test_datas = [neg_doc[20000:], pos_doc[20000:]]\n",
    "    \n",
    "    \n",
    "    return [' '.join(train_datas[0]), ' '.join(train_datas[1])], [' '.join(test_datas[0]), ' '.join(test_datas[1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def naive_bayes(train_datas, test_data, pos_prob, neg_prob):\n",
    "    test_pos_prob = calculate_doc_prob(train_datas[1], test_data, 0.1) + log(pos_prob) \n",
    "    test_neg_prob = calculate_doc_prob(train_datas[0], test_data, 0.1) + log(neg_prob)\n",
    "     \n",
    "    maxprob = max(test_neg_prob, test_pos_prob)\n",
    "    test_pos_prob -= maxprob\n",
    "    test_neg_prob -= maxprob\n",
    "    test_pos_prob = exp(test_pos_prob)\n",
    "    test_neg_prob = exp(test_neg_prob)\n",
    "    normalized_prob = [test_neg_prob/(test_neg_prob+test_pos_prob), test_pos_prob/(test_neg_prob+test_pos_prob)]\n",
    "    \n",
    "    return normalized_prob\n",
    "\n",
    "\n",
    "\n",
    "def calculate_doc_prob(train_data, test_data, nowords_weight):\n",
    "    log_prob = 0 \n",
    "        \n",
    "   \n",
    "    sw_train_data = re.compile(\"[^\\w]\").sub(' ', train_data.lower())\n",
    "\n",
    "    sw_train_token = sw_train_data.split() \n",
    "    train_vector = dict(Counter(sw_train_token))\n",
    "    \n",
    "\n",
    "    sw_test_data = re.compile(\"[^\\w]\").sub(' ', test_data.lower())\n",
    "    sw_test_token = sw_test_data.split()\n",
    "    test_vector = dict(Counter(sw_test_token)) \n",
    "    \n",
    "   \n",
    "    total_wc = len(sw_train_token)\n",
    "    \n",
    "    for word in test_vector:\n",
    "        if word in train_vector:\n",
    "            log_prob += log(train_vector[word]/total_wc)\n",
    "        else:\n",
    "            log_prob += log(nowords_weight/total_wc) \n",
    "            \n",
    "    return log_prob\n",
    "\n",
    "start_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
