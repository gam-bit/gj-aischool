{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4loDgTiMMU5u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks/mecab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmsbRVe9Mhu0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "fjltD63TMjt0",
    "outputId": "1d3db531-b086-4df4-f574-f8371ebb7469"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data = pd.read_table('../ratings.txt')\n",
    "ratings_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "B-cSaGlKNlcB",
    "outputId": "68a24511-7fcc-488a-c34d-7cca7c126768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        200000 non-null  int64 \n",
      " 1   document  199992 non-null  object\n",
      " 2   label     200000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-5vRY3oW-vs"
   },
   "source": [
    "# 1. LSTM 복습. naver 리뷰(split을 이용한 토크나이즈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "CDIP5AliNpJ7",
    "outputId": "f715b234-de72-4a40-c628-e4cfae9e3828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# preprocessing done\n",
      "# split done\n",
      "# tokenization done\n",
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "# 전처리---------------------------------------------\n",
    "ratings_data['document'] = ratings_data['document'].str.replace(r'[^\\w]', ' ')\n",
    "ratings_data['document'] = ratings_data['document'].replace('', np.nan)\n",
    "ratings_data = ratings_data.dropna(how='any', axis=0)\n",
    "print(\"# preprocessing done\")\n",
    "\n",
    "\n",
    "# 토크나이즈-----------------------------------------\n",
    "docu_train, docu_test, y_train, y_test = train_test_split(ratings_data['document'], ratings_data['label'], shuffle=False)\n",
    "print(\"# split done\")\n",
    "\n",
    "X_train = []\n",
    "for stc in docu_train:\n",
    "    X_train.append(stc.split())\n",
    "  \n",
    "X_test = []\n",
    "for stc in docu_test:\n",
    "    X_test.append(stc.split())\n",
    "\n",
    "print(\"# tokenization done\")\n",
    "\n",
    "# 정수 인코딩----------------------------------------\n",
    "# 토크나이저는 빈도수가 높은 것부터 인덱스를 부여함\n",
    "tokenizer = Tokenizer()  # 단어 설정을 안하면 전체 단어가 들어감\n",
    "                         # 쓸데없는 단어까지 다 들어가게 되는데,\n",
    "                         # 그렇게 되면 loss가 늘어나게 된다.\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(\"# int_encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zrq2VV2ytYkQ",
    "outputId": "3b9276d6-2a68-4c91-ddcf-43bf69eced43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288992\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.word_index)) # 전체 단어 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8nGUkJ1Vtj8T",
    "outputId": "fc83e285-ee0c-4ad6-fc9e-e077ab50e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246329\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 2이하인 단어의 개수\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "  if word_count <= 2:\n",
    "    low_count += 1\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5JdFybDbtxFs",
    "outputId": "46693db8-98ba-4f35-bc44-1663b77f2ea7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42663"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index) - low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "juRFuBz3uWj8",
    "outputId": "490944b0-1270-4129-cf4a-6c54d55a76fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "# max_length 구하기\n",
    "max_length = 0\n",
    "for data in X_train:\n",
    "      if max_length < len(data):\n",
    "          max_length = len(data)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OXPi9Ta2O3I_",
    "outputId": "a73837e5-0438-487b-c309-50129f833e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# padding done\n"
     ]
    }
   ],
   "source": [
    "# padding---------------------------------------------\n",
    "max_len = max([len(x) for x in X_train]) # 문장의 최대 길이 or 평균 길이\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "print(\"# padding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scnXyIhEXjK8"
   },
   "outputs": [],
   "source": [
    "# 모델 생성-------------------------------------------\n",
    "\n",
    "model = Sequential()\n",
    "# 단어 임베딩 -> 5000개의 단어를 120차원으로 내보내겠다(정수 -> 120 dimension vector)\n",
    "\n",
    "# LSTM에서는 120~128 dimension일 때 성능이 제일 좋다는 경험적 성과가 있음\n",
    "# dimension은 hyperparameter\n",
    "# 긴 문장은 높게, 짧은 문장은 작게 잡는 편임\n",
    "# 보통 2의 거듭제곱 형태로 지정한다.\n",
    "\n",
    "model.add(Embedding(20000, 120))\n",
    "# LSTM\n",
    "model.add(LSTM(120))\n",
    "# 이진 분류(sigmoid)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GprLK53O270"
   },
   "outputs": [],
   "source": [
    "# # 모델 성능 향상---------------------------------------\n",
    "\n",
    "# # validation loss를 계속 보다가 5회 이상 loss가 증가하면, 과적합될 수 있으므로 학습을 조기 종료하겠다.\n",
    "# early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# # epoch를 반복하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트(the_best.h5)로 저장\n",
    "# # 정확도가 낮아지면 모델 버려라\n",
    "# model_check = ModelCheckpoint('the_best_korean_split.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMDtsXuCNrAb"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[early_stop, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zQgRFhPOue1"
   },
   "outputs": [],
   "source": [
    "# # 정확도 측정\n",
    "# print(model.evaluate(X_test, y_test)) # [loss, acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkyJ_rEHNrEn"
   },
   "source": [
    "# 2. [캐글 스팸데이터](https://www.kaggle.com/uciml/sms-spam-collection-dataset)를 활용한 스팸 메일 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "U-Hd-A3INrWE",
    "outputId": "6169c0db-90e8-4bc7-d156-6cf965136aae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  ... Unnamed: 4\n",
       "0   ham  ...        NaN\n",
       "1   ham  ...        NaN\n",
       "2  spam  ...        NaN\n",
       "3   ham  ...        NaN\n",
       "4   ham  ...        NaN\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv('../spam.csv', encoding='latin1')\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRu5AGcNxYlQ"
   },
   "outputs": [],
   "source": [
    "spam = spam.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hL-Y6lqyyYic",
    "outputId": "42b769a0-3e3c-428e-f342-29a292d3a5d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1    0\n",
       "v2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Hn5jEAZFzgNy",
    "outputId": "efd68345-0d5b-44e4-d4f6-eb85fa53e8fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.v1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "m3tjVQ-UxYqt",
    "outputId": "4dff6c88-87ca-4fc3-8a47-2c66d520a3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# preprocessing done\n",
      "# split done\n",
      "# tokenization done\n"
     ]
    }
   ],
   "source": [
    "# v1 전처리(y)\n",
    "# -- 숫자로 변환\n",
    "spam['v1'] = spam['v1'].replace('ham', 0)\n",
    "spam['v1'] = spam['v1'].replace('spam', 1)\n",
    "\n",
    "# v2 전처리(X)\n",
    "# -- 단어만 남기기\n",
    "spam['v2'] = spam['v2'].str.replace(r\"[^\\w]\", ' ')\n",
    "spam['v2'] = spam['v2'].replace('', np.nan)\n",
    "spam['v2']\n",
    "# print(spam.shape)\n",
    "\n",
    "# -- null인 행 제거\n",
    "spam = spam.dropna(how='any', axis=0)\n",
    "# print(spam.shape)\n",
    "\n",
    "# -- 소문자로 변경\n",
    "spam['v2'] = spam['v2'].apply(lambda x: x.lower())\n",
    "\n",
    "print(\"# preprocessing done\")\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "mail_train, mail_test, y_train, y_test = train_test_split(spam['v2'], spam['v1'], shuffle=False)\n",
    "\n",
    "print('# split done')\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "stopwords = ['the', 'a', 'an', 'i', 'my', 'me', 'mine', 'you', 'your', 'yours', 'she', 'her', 'hers', 'he', 'his', 'him']\n",
    "\n",
    "X_train = []\n",
    "for stc in mail_train:\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            words.remove(word)\n",
    "    X_train.append(words)\n",
    "\n",
    "X_test = []\n",
    "for stc in mail_test:\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            words.remove(word)\n",
    "    X_test.append(words)\n",
    "\n",
    "\n",
    "print(\"# tokenization done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "eqgtanOyxY5K",
    "outputId": "e543bfe5-c82b-4285-f9bc-73ecbe8ebdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 token 개수: 7512\n",
      "빈도수가 3이하인 token 개수: 5658\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(\"전체 token 개수:\", len(tokenizer.word_index))\n",
    "print(\"빈도수가 3이하인 token 개수:\", len([word for word, word_count in tokenizer.word_counts.items() if word_count <= 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1AAA6Rf18p88",
    "outputId": "53b8eba3-29aa-4d25-9ac3-1e2b5af86095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# int-encoding done\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "tokenizer = Tokenizer(1800)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(\"# int-encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VR46qfKd8qC4",
    "outputId": "005b9dfc-5391-4693-9620-0fb99a70fbea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# padding done\n"
     ]
    }
   ],
   "source": [
    "# padding--------------------------------------------------------------------\n",
    "max_len = max([len(x) for x in X_train]) # 137\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "print(\"# padding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nfeSM-__J2d"
   },
   "outputs": [],
   "source": [
    "# 모델 생성----------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Embedding(1800, 128, input_length=max_len))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# callback-----------------------------------------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model_check = ModelCheckpoint('LSTM_spam_best.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "uZZ30WKYAWwH",
    "outputId": "d6da7b1f-a9ba-4672-8cd7-6061b261ee9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9174\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98277, saving model to LSTM_spam_best.h5\n",
      "66/66 [==============================] - 23s 346ms/step - loss: 0.2317 - accuracy: 0.9174 - val_loss: 0.0605 - val_accuracy: 0.9828\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9878\n",
      "Epoch 00002: val_accuracy improved from 0.98277 to 0.98995, saving model to LSTM_spam_best.h5\n",
      "66/66 [==============================] - 23s 350ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.0388 - val_accuracy: 0.9899\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9940\n",
      "Epoch 00003: val_accuracy did not improve from 0.98995\n",
      "66/66 [==============================] - 22s 339ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.0397 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 00004: val_accuracy did not improve from 0.98995\n",
      "66/66 [==============================] - 22s 340ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.0551 - val_accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9978\n",
      "Epoch 00005: val_accuracy did not improve from 0.98995\n",
      "66/66 [==============================] - 22s 338ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0531 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9981\n",
      "Epoch 00006: val_accuracy did not improve from 0.98995\n",
      "66/66 [==============================] - 22s 340ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0661 - val_accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9981\n",
      "Epoch 00007: val_accuracy did not improve from 0.98995\n",
      "66/66 [==============================] - 22s 340ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.0501 - val_accuracy: 0.9856\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1afd0b8898>"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습----------------------------------------------------------------\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[early_stop, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "0HeijUR0_J-b",
    "outputId": "0a0b95c5-bcb6-40fc-8a8f-238bdb450061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 42ms/step - loss: 0.0501 - accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.050080396234989166, 0.9856424927711487]"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가------------------------------------------------------------\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "e-N-wADs_KBm",
    "outputId": "96502bd1-d391-41bb-ba6a-1aeffe84c8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0c3f084c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.99090266]]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 데이터 평가\n",
    "model = load_model('LSTM_spam_best.h5')\n",
    "sentence = input()\n",
    "\n",
    "# 토큰화\n",
    "token_stc = sentence.split()\n",
    "token_stc = [word.lower() for word in token_stc]\n",
    "\n",
    "# 정수 인코딩\n",
    "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
    "\n",
    "# 패딩\n",
    "pad_stc = pad_sequences(encode_stc, maxlen=max_len)\n",
    "\n",
    "score = model.predict(pad_stc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRuzOio_xY-x"
   },
   "source": [
    "에러 무엇?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_SF5De-zfap"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "12_LSTM_spam",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
