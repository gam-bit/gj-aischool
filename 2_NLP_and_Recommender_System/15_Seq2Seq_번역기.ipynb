{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_Seq2Seq_번역기.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxuQVagwv1a9",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VUGlkdZv7fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ-QWGPjwvBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mgSrdhuuFOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "89db6407-56de-4829-bcdd-a1d52f93b81c"
      },
      "source": [
        "pd.read_csv('./data/par_corp.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[1]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#The order went forth that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#명령은 아래와 같이 반포되었다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#The orders must be strictly obeyed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#명령은 반드시 엄격히 준수해야 한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142995</th>\n",
              "      <td>#The wet shirt clung to his body.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142996</th>\n",
              "      <td>#젖은 셔츠가 그의 몸에 착 달라붙어있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142997</th>\n",
              "      <td>[1021]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142998</th>\n",
              "      <td>#Damp matches won't strike.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142999</th>\n",
              "      <td>#젖은 성냥은 그어도 켜지지 않는다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         [1]\n",
              "0              #The order went forth that...\n",
              "1                         #명령은 아래와 같이 반포되었다.\n",
              "2                                        [2]\n",
              "3       #The orders must be strictly obeyed.\n",
              "4                      #명령은 반드시 엄격히 준수해야 한다.\n",
              "...                                      ...\n",
              "142995     #The wet shirt clung to his body.\n",
              "142996               #젖은 셔츠가 그의 몸에 착 달라붙어있다.\n",
              "142997                                [1021]\n",
              "142998           #Damp matches won't strike.\n",
              "142999                  #젖은 성냥은 그어도 켜지지 않는다.\n",
              "\n",
              "[143000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhXzdfWw6_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "34305b65-ef9e-4c3f-8a5a-1d21777e0a23"
      },
      "source": [
        "files = open('./data/par_corp.csv')\n",
        "\n",
        "re_lines = []\n",
        "for line in files:\n",
        "    if line[0] == '[': \n",
        "        continue\n",
        "    re_line = re.sub('[#\".?!\\n]', '', line)\n",
        "    re_lines.append(re_line)\n",
        "\n",
        "# print(re_lines[:10])    \n",
        "\n",
        "kor = []\n",
        "eng = []\n",
        "count = 0\n",
        "for line in re_lines:\n",
        "    count = count + 1\n",
        "    if count % 2 == 0:\n",
        "        kor.append(line)\n",
        "    else:\n",
        "        eng.append(line)\n",
        "\n",
        "\n",
        "data_dict = {'kor': kor, 'eng': eng}\n",
        "par_corp = pd.DataFrame(data_dict)\n",
        "\n",
        "print(par_corp)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          kor                                        eng\n",
            "0            명령은 아래와 같이 반포되었다                  The order went forth that\n",
            "1         명령은 반드시 엄격히 준수해야 한다         The orders must be strictly obeyed\n",
            "2       운명의 여신은 용사를 특별히 애호하신다                  fortune favors the brave \n",
            "3         운명에 그가 죽을 것이라고 정해졌다            Fate destined that he shall die\n",
            "4      운명에 그는 목사가 될 것이라고 정해졌다         Fate had ordained him to die young\n",
            "...                       ...                                        ...\n",
            "47662              사자는 야생동물이다                  The lion is a wild animal\n",
            "47663            사자는 황야로 도망갔다  The lion escaped and returned to the wild\n",
            "47664   사자는 우리 안에서 천천히 왔다갔다한다       The lion paced the floor of its cage\n",
            "47665   젖은 셔츠가 그의 몸에 착 달라붙어있다            The wet shirt clung to his body\n",
            "47666      젖은 성냥은 그어도 켜지지 않는다                  Damp matches won't strike\n",
            "\n",
            "[47667 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXEAy83nwmkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input, decoder_input, decoder_output = [], [], []\n",
        "\n",
        "for stc in par_corp['kor']:\n",
        "    encoder_input.append(stc.split())\n",
        "\n",
        "for stc in par_corp['eng']:\n",
        "    decoder_input.append((\"<start> \" + stc).split())\n",
        "\n",
        "for stc in par_corp['eng']:\n",
        "    decoder_output.append((stc+' <end>').split())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shtgKLczzaI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "6ad3569a-1746-4c1b-c872-21c77f4e503a"
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['명령은', '아래와', '같이', '반포되었다'], ['명령은', '반드시', '엄격히', '준수해야', '한다'], ['운명의', '여신은', '용사를', '특별히', '애호하신다']]\n",
            "[['<start>', 'The', 'order', 'went', 'forth', 'that'], ['<start>', 'The', 'orders', 'must', 'be', 'strictly', 'obeyed'], ['<start>', 'fortune', 'favors', 'the', 'brave']]\n",
            "[['The', 'order', 'went', 'forth', 'that', '<end>'], ['The', 'orders', 'must', 'be', 'strictly', 'obeyed', '<end>'], ['fortune', 'favors', 'the', 'brave', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4toZdRHzlSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정수 인코딩\n",
        "tokenizer_ko = Tokenizer()\n",
        "tokenizer_ko.fit_on_texts(encoder_input)\n",
        "encoder_input = tokenizer_ko.texts_to_sequences(encoder_input)\n",
        "\n",
        "tokenizer_en = Tokenizer()\n",
        "tokenizer_en.fit_on_texts(decoder_input)\n",
        "tokenizer_en.fit_on_texts(decoder_output)\n",
        "decoder_input = tokenizer_en.texts_to_sequences(decoder_input)\n",
        "decoder_output = tokenizer_en.texts_to_sequences(decoder_output)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhUoEK060B4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "62dad4ba-d9f5-4bb3-c723-ef9298ed2ff9"
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10325, 1216, 312, 23138], [10325, 66, 8026, 6543, 12], [8027, 23139, 23140, 1162, 23141]]\n",
            "[[2, 1, 175, 97, 670, 19], [2, 1, 761, 78, 31, 2133, 11983], [2, 1324, 6699, 1, 2852]]\n",
            "[[1, 175, 97, 670, 19, 3], [1, 761, 78, 31, 2133, 11983, 3], [1324, 6699, 1, 2852, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu03apfAyhrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f7d7cbce-8440-48a6-a372-1994e2649f8c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "len_ko = [len(x) for x in encoder_input]\n",
        "len_en = [len(x) for x in decoder_input]\n",
        "\n",
        "plt.hist(len_ko, label='ko', alpha=0.7)\n",
        "plt.hist(len_en, label='en', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# 번역은 손실이 조금만 생겨도 번역이 잘못될 수 있기 때문에 평균값보다는 max값을 사용"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM6QbriD1UsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# maxlen의 default는 알아서 maxlen으로 들어감\n",
        "encoder_input = pad_sequences(encoder_input, padding='post') # end 뒤는 보지 않도록 post를 지정해야 함\n",
        "decoder_input = pad_sequences(decoder_input, padding='post')\n",
        "decoder_output = pad_sequences(decoder_output, padding='post')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zeyMPtA1n6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f07b9c1e-8586-4d13-9b59-f0c9892feefa"
      },
      "source": [
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47667, 27)\n",
            "(47667, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHQ7DhnZyh5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단어 <-> index 변환용 \n",
        "en_to_index = tokenizer_en.word_index\n",
        "index_to_en = tokenizer_en.index_word"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGfXnI7l2bO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split train, test (3:1)\n",
        "test_size = 12000 # 전체 48000개 중\n",
        "encoder_input_train = encoder_input[:-test_size]\n",
        "decoder_input_train = decoder_input[:-test_size]\n",
        "decoder_output_train = decoder_output[:-test_size]\n",
        "\n",
        "encoder_input_test = encoder_input[-test_size:]\n",
        "decoder_input_test = decoder_input[-test_size:]\n",
        "decoder_output_test = decoder_output[-test_size:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmJdy2Oj2uLr",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK45-QB620Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXt9D8iz3rDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더 모델 - 한글 문장을 받아서 LSTM의 은닉/셀 상태를 리턴\n",
        "encoder_inputs = Input(shape=(27,))  # padding 후 길이 \n",
        "encoder_embed = Embedding(len(tokenizer_ko.word_index)+1, 50)(encoder_inputs) # 50은 hyperparameter\n",
        "encoder_mask = Masking(mask_value=0)(encoder_embed) # 0인 값은 버리고 봐라\n",
        "\n",
        "# LSTM\n",
        "# return_state=True를 통해 마지막 은닉 상태/마지막 셀 상태 값을 리턴\n",
        "# LSTM 한 시점의 출력은 은닉 상태값 -> 이것이 softmax 같은 함수를 통과하면서 y가 됨\n",
        "encoder_output, h_state, c_state = LSTM(50, return_state=True)(encoder_mask) # encoder_output = h_state"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWXjVWrN6NAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 모델 - 인코더 상태 값과, 영어 단어 입력을 받아서 LSTM의 출력값(은닉 상태)을 받아서 softmax 함수를 통과시키면 y가 출력됨\n",
        "decoder_inputs = Input(shape=(27,))\n",
        "decoder_embed = Embedding(len(tokenizer_en.word_index)+1, 50)(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
        "\n",
        "# return_sequences는 전체 시점의 은닉 상태 값만을 리턴(각 단어 인풋 별 은닉 상태 값)\n",
        "# 아래의 코드는 return_state, return_sequences를 모두 사용했기 때문에\n",
        "# 전체 시점의 은닉 상태 값/마지막 은닉 상태값/마지막 셀 상태 값이 리턴됨\n",
        "# >> return state는 마지막 h,c만, return sequence는 매 시점마다의 h\n",
        "\n",
        "# prediction을 위해서 함수형으로 사용하지 않고 layer를 저장해서 사용\n",
        "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
        "# decoder는 마지막 시점의 은닉/셀 상태 값이 중요하지 않아서 더미 변수로 받음\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n",
        "decoder_dense = Dense(len(tokenizer_en.word_index)+1, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hILkHWcr2Lad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# sparse는 라벨(y)이 정수 형태로 제공될 때, categorical은 one-hot vector로 제공될 때 사용\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhAef9d12Le-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "59ad81b2-7bdb-458a-a158-0a03408d367a"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = 128, epochs=50, callbacks=[early_stop])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "279/279 [==============================] - 64s 228ms/step - loss: 3.4443 - accuracy: 0.6885 - val_loss: 2.2692 - val_accuracy: 0.6918\n",
            "Epoch 2/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.9778 - accuracy: 0.7301 - val_loss: 2.1963 - val_accuracy: 0.6968\n",
            "Epoch 3/50\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.9077 - accuracy: 0.7374 - val_loss: 2.1290 - val_accuracy: 0.7050\n",
            "Epoch 4/50\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.8500 - accuracy: 0.7412 - val_loss: 2.0837 - val_accuracy: 0.7077\n",
            "Epoch 5/50\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.8046 - accuracy: 0.7443 - val_loss: 2.0462 - val_accuracy: 0.7098\n",
            "Epoch 6/50\n",
            "279/279 [==============================] - 62s 220ms/step - loss: 1.7614 - accuracy: 0.7489 - val_loss: 2.0140 - val_accuracy: 0.7165\n",
            "Epoch 7/50\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.7213 - accuracy: 0.7533 - val_loss: 1.9825 - val_accuracy: 0.7199\n",
            "Epoch 8/50\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.6903 - accuracy: 0.7566 - val_loss: 1.9713 - val_accuracy: 0.7213\n",
            "Epoch 9/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.6657 - accuracy: 0.7591 - val_loss: 1.9562 - val_accuracy: 0.7225\n",
            "Epoch 10/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.6439 - accuracy: 0.7614 - val_loss: 1.9484 - val_accuracy: 0.7239\n",
            "Epoch 11/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.6222 - accuracy: 0.7642 - val_loss: 1.9502 - val_accuracy: 0.7240\n",
            "Epoch 12/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.6018 - accuracy: 0.7669 - val_loss: 1.9269 - val_accuracy: 0.7266\n",
            "Epoch 13/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.5830 - accuracy: 0.7689 - val_loss: 1.9253 - val_accuracy: 0.7273\n",
            "Epoch 14/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.5660 - accuracy: 0.7708 - val_loss: 1.9209 - val_accuracy: 0.7284\n",
            "Epoch 15/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.5499 - accuracy: 0.7725 - val_loss: 1.9251 - val_accuracy: 0.7289\n",
            "Epoch 16/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.5354 - accuracy: 0.7742 - val_loss: 1.9232 - val_accuracy: 0.7291\n",
            "Epoch 17/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.5214 - accuracy: 0.7759 - val_loss: 1.9213 - val_accuracy: 0.7290\n",
            "Epoch 18/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.5083 - accuracy: 0.7774 - val_loss: 1.9257 - val_accuracy: 0.7287\n",
            "Epoch 19/50\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.4946 - accuracy: 0.7788 - val_loss: 1.9382 - val_accuracy: 0.7291\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3a3876d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBtmcLkUSKuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "# model.save('par_corp_seq2seq_epochs_50.h5')\n",
        "# model = load_model('par_corp_seq2seq_epochs_50.h5') # loss: 1.2487 - accuracy: 0.8153 - val_loss: 2.1738 - val_accuracy: 0.7183"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4mRaQy62K1L",
        "colab_type": "text"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "- train할 때는 decoder input을 알지만, prediction으로 할 땐 decoder input을 몰라서. 모델만 가지고 prediction을 할 수 없음. process 만들어줘야 함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij0s06-BCx6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더가 출력하는 마지막 시점의 셀/은닉 상태 값을 따로 구하고\n",
        "# <start> 라는 인풋을 따로 디코더 모델(lstm)에 넣어서\n",
        "# 디코더 모델(lstm)에서 내는 output을 다시 디코더 모델(lstm)에 계속 넣어주는 형태로 구현\n",
        "# 그러다가 <end>가 나타나면 멈춘다\n",
        " \n",
        "# 가중치는 model train에서 레이어별로 학습되어있으므로 이 가중치를 가져와서 사용함.\n",
        "encoder_model = Model(encoder_inputs, [h_state, c_state]) # input, output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAS2xoPr_sr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 모델\n",
        "  # decoder에서는 시퀀스를 넣는 것이 아니라, 단어를 하나씩 넣을 것 \n",
        "  # 따라서 상태값(h)이 자동으로 넘겨지지 않아서 직접 넘겨줘야 한다. \n",
        "encoder_h_state = Input(shape=(50,)) # lstm output_dim = 50\n",
        "encoder_c_state = Input(shape=(50,)) \n",
        "\n",
        "pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state]) # 위에서 학습한 결과를 사용\n",
        "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_outputs)\n",
        "  # 디코더 인풋(단어 1개), 인코더의 상태값이 인풋으로 들어감\n",
        "  # lstm 셀을 통과하면서 예측, softmax 함수를 통과한 출력값(단어별 확률값)과 디코더의 상태값을 각각 출력해야 함\n",
        "  # softmax 함수를 통과한 출력값(확률)을 토대로 다음 단어를 확정\n",
        "  # 확정된 단어와 전 단계의 디코더의 상태값이 다음 인풋으로 들어간다.\n",
        "    # input에 있는 [encoder_h_state, encoder_c_state]는 단계가 넘어가면 전 단계에 대한 h_state, c_state를 의미하게 됨\n",
        "decoder_model = Model([decoder_inputs] + [encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs] + [pd_h_state, pd_c_state])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGaHx7Sd_sx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7f7a2c87-7ab0-4732-83d0-fb006da2edd5"
      },
      "source": [
        "input_stc = input()\n",
        "token_stc = input_stc.split()\n",
        "encode_stc = tokenizer_ko.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=27, padding='post')\n",
        "\n",
        "states_value = encoder_model.predict(pad_stc)\n",
        "\n",
        "predicted_seq = np.zeros((1, 1)) \n",
        "predicted_seq[0, 0] = en_to_index['<start>']\n",
        "\n",
        "decoded_stc = []\n",
        "\n",
        "while True:\n",
        "    output_words, h, c = decoder_model.predict([predicted_seq] + states_value)\n",
        "    # print(output_words[0,0])\n",
        "\n",
        "    predicted_word = index_to_en[np.argmax(output_words[0,0])]\n",
        "    \n",
        "    if predicted_word == '<end>':\n",
        "        break\n",
        "\n",
        "    decoded_stc.append(predicted_word)\n",
        "    \n",
        "    predicted_seq = np.zeros((1, 1))\n",
        "    predicted_seq[0, 0] = np.argmax(output_words[0, 0])  \n",
        "    states_value = [h, c]\n",
        "\n",
        "print(' '.join(decoded_stc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "젖은 성냥은 그어도 켜지지 않는다\n",
            "the cat is the wall of the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S56WdZGyiP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}