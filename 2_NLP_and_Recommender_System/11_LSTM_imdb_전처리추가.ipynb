{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DJHvkn0FAp8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtUepBI6FHRU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "pKHZoi2kFYpx",
    "outputId": "f2c5cfc7-c224-46ae-df05-fab8212a7a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "imdb_data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "print(imdb_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "KY785QlCFo9o",
    "outputId": "540f5340-12ee-4860-8627-852e805bb1eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# preprocessing done\n",
      "# split done\n",
      "# tokenization done\n",
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "# pos, neg 값을 숫자로 변형(1, 0)\n",
    "imdb_data['sentiment'] = imdb_data['sentiment'].replace('positive', 1)\n",
    "imdb_data['sentiment'] = imdb_data['sentiment'].replace('negative', 0)\n",
    "\n",
    "\n",
    "# 전처리---------------------------------------------------------------\n",
    "# 1) 단어가 아니면 삭제\n",
    "imdb_data['review'] = imdb_data['review'].str.replace(\"[^\\w]|br\", \" \")\n",
    "# 2) 공백만 있는 경우 null array로 변환\n",
    "imdb_data['review'] = imdb_data['review'].replace('', np.nan)\n",
    "imdb_data['sentiment'] = imdb_data['sentiment'].replace('', np.nan)\n",
    "# 3) null인 행 제거\n",
    "imdb_data = imdb_data.dropna(how='any', axis=0)\n",
    "print(\"# preprocessing done\")\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "review_train, review_test, y_train, y_test = train_test_split(imdb_data['review'], imdb_data['sentiment'], shuffle=False, random_state=34)\n",
    "     # default : test_size = 0.25\n",
    "print(\"# split done\")\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# 리뷰 문장 -> 토크나이즈(using split)\n",
    "stopwords = ['a', 'an', 'the']\n",
    "\n",
    "X_train = []\n",
    "for stc in review_train:\n",
    "    token = []\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "      if word not in stopwords:\n",
    "        token.append(word)\n",
    "    X_train.append(token)\n",
    "\n",
    "X_test = []\n",
    "for stc in review_test:\n",
    "    token = []\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "      if word not in stopwords:\n",
    "        token.append(word)\n",
    "    X_test.append(token)\n",
    "print(\"# tokenization done\")\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "# 단어 -> 정수 인코딩\n",
    "# 임베딩 전 컴퓨터가 단어를 구별할 수 있도록 함. OHE로 바꿔서 하는 것과 동일한 맥락\n",
    "tokenizer = Tokenizer(5000)\n",
    "tokenizer.fit_on_texts(X_train) # 각 단어에 정수 인덱스를 부여\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(\"# int_encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qx1epSRqF78-"
   },
   "outputs": [],
   "source": [
    "# 문장마다 길이가 다르므로 길이를 맞춰주기\n",
    "# 문장마다 embedding layer를 통과하게 할 것이기 때문\n",
    "\n",
    "# max_len은 데이터셋을 보면서 최대 문장의 길이로 설정\n",
    "# max_len = max([len(x) for x in X_train]) # 1743\n",
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len) # 더 길면 자르고, 짧으면 0을 추가\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "HsZKxGFbGYsK",
    "outputId": "6cc95310-3e5e-40da-d8a2-9d8e83827469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    1   14   22   16   43  530  973 1622 1385   65  458 4468\n",
      "   66 3941    4  173   36  256    5   25  100   43  838  112   50  670\n",
      "    2    9   35  480  284    5  150    4  172  112  167    2  336  385\n",
      "   39    4  172 4536 1111   17  546   38   13  447    4  192   50   16\n",
      "    6  147 2025   19   14   22    4 1920 4613  469    4   22   71   87\n",
      "   12   16   43  530   38   76   15   13 1247    4   22   17  515   17\n",
      "   12   16  626   18    2    5   62  386   12    8  316    8  106    5\n",
      "    4 2223    2   16  480   66 3785   33    4  130   12   16   38  619\n",
      "    5   25  124   51   36  135   48   25 1415   33    6   22   12  215\n",
      "   28   77   52    5   14  407   16   82    2    8    4  107  117    2\n",
      "   15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
      "  400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
      "   98   32 2071   56   26  141    6  194    2   18    4  226   22   21\n",
      "  134  476   26  480    5  144   30    2   18   51   36   28  224   92\n",
      "   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      " 4472  113  103   32   15   16    2   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrCnp-OiGayj"
   },
   "outputs": [],
   "source": [
    "# 모델 생성-------------------------------------------\n",
    "\n",
    "model = Sequential()\n",
    "# 단어 임베딩 -> 5000개의 단어를 120차원으로 내보내겠다(정수 -> 120 dimension vector)\n",
    "model.add(Embedding(5000, 120))\n",
    "# LSTM\n",
    "model.add(LSTM(120))\n",
    "# 이진 분류(sigmoid)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYyWuOSlGixR"
   },
   "outputs": [],
   "source": [
    "# 모델 성능 향상---------------------------------------\n",
    "\n",
    "# validation loss를 계속 보다가 5회 이상 loss가 증가하면, 과적합될 수 있으므로 학습을 조기 종료하겠다.\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# epoch를 반복하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트(the_best_imdb.h5)로 저장\n",
    "# 정확도가 낮아지면 모델 버려라\n",
    "model_check = ModelCheckpoint('the_best_imdb.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "fAtpX6-TH6PG",
    "outputId": "d37ffbc0-e5ef-4e2b-90a6-2eb5906f170d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4408 - acc: 0.7887\n",
      "Epoch 00001: val_acc improved from -inf to 0.84736, saving model to the_best.h5\n",
      "391/391 [==============================] - 521s 1s/step - loss: 0.4408 - acc: 0.7887 - val_loss: 0.3623 - val_acc: 0.8474\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2779 - acc: 0.8892\n",
      "Epoch 00002: val_acc improved from 0.84736 to 0.87568, saving model to the_best.h5\n",
      "391/391 [==============================] - 524s 1s/step - loss: 0.2779 - acc: 0.8892 - val_loss: 0.2991 - val_acc: 0.8757\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2259 - acc: 0.9136\n",
      "Epoch 00003: val_acc did not improve from 0.87568\n",
      "391/391 [==============================] - 521s 1s/step - loss: 0.2259 - acc: 0.9136 - val_loss: 0.3076 - val_acc: 0.8718\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1977 - acc: 0.9246\n",
      "Epoch 00004: val_acc improved from 0.87568 to 0.87756, saving model to the_best.h5\n",
      "391/391 [==============================] - 522s 1s/step - loss: 0.1977 - acc: 0.9246 - val_loss: 0.3229 - val_acc: 0.8776\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1646 - acc: 0.9389\n",
      "Epoch 00005: val_acc did not improve from 0.87756\n",
      "391/391 [==============================] - 522s 1s/step - loss: 0.1646 - acc: 0.9389 - val_loss: 0.3809 - val_acc: 0.8444\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1802 - acc: 0.9286\n",
      "Epoch 00006: val_acc did not improve from 0.87756\n",
      "391/391 [==============================] - 516s 1s/step - loss: 0.1802 - acc: 0.9286 - val_loss: 0.3696 - val_acc: 0.8673\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1275 - acc: 0.9536\n",
      "Epoch 00007: val_acc did not improve from 0.87756\n",
      "391/391 [==============================] - 516s 1s/step - loss: 0.1275 - acc: 0.9536 - val_loss: 0.4950 - val_acc: 0.8315\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f11d4c19278>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[early_stop, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDHQp_gn7eJs"
   },
   "outputs": [],
   "source": [
    "# # 모델 불러오기\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model('the_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "QbbAfHKtGjJs",
    "outputId": "d90055e0-1458-434c-9d1e-422e8906e384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 100s 128ms/step - loss: 0.3229 - acc: 0.8776\n",
      "[0.32294711470603943, 0.877560019493103]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정\n",
    "print(model.evaluate(X_test, y_test)) # [loss, acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAm6Ner8GjRY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GHKn4O781FX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExJtSAxSGjUl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_LSTM_imdb_전처리 추가.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
