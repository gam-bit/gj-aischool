{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_CNN_imdb_함수형, 서브클래스형api",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DJHvkn0FAp8"
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtUepBI6FHRU"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Conv1D, GlobalMaxPooling1D, Flatten, Concatenate, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKHZoi2kFYpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71faf757-7240-4fdb-f203-acbf3e551c26"
      },
      "source": [
        "imdb_data = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "print(imdb_data.head())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQB4Opsbzp2"
      },
      "source": [
        "# y값 지정 : pos = 1, neg = 0으로 변형\r\n",
        "imdb_data['sentiment'] = imdb_data['sentiment'].replace('positive', 1)\r\n",
        "imdb_data['sentiment'] = imdb_data['sentiment'].replace('negative', 0)\r\n",
        "\r\n",
        "# 전처리\r\n",
        "## 1) 단어 아니면 삭제\r\n",
        "imdb_data['review'] = imdb_data['review'].str.replace('[^\\w]|br', ' ') \r\n",
        "## 2) 공백만 있는 경우 null array로 변환 후 제거\r\n",
        "imdb_data['review'] = imdb_data['review'].replace('', np.nan)\r\n",
        "imdb_data['sentiment'] = imdb_data['sentiment'].replace('', np.nan)\r\n",
        "imdb_data = imdb_data.dropna(how='any', axis=0)\r\n",
        "\r\n",
        "# train, test 분리\r\n",
        "review_train_full, review_test, y_train_full, y_test = train_test_split(imdb_data['review'], imdb_data['sentiment'], shuffle=False, random_state=34)\r\n",
        "review_train, review_valid, y_train, y_valid = train_test_split(review_train_full, y_train_full, shuffle=False, random_state=34)\r\n",
        "\r\n",
        "# 토큰화\r\n",
        "stopwords = ['a', 'an', 'the']\r\n",
        "\r\n",
        "X_train = []\r\n",
        "for stc in review_train:\r\n",
        "    token = []\r\n",
        "    words = stc.split()\r\n",
        "    for word in words:\r\n",
        "        if word not in stopwords:\r\n",
        "            token.append(word)\r\n",
        "    X_train.append(token)\r\n",
        "\r\n",
        "X_valid = []\r\n",
        "for stc in review_valid:\r\n",
        "    token = []\r\n",
        "    words = stc.split()\r\n",
        "    for word in words:\r\n",
        "        if word not in stopwords:\r\n",
        "            token.append(word)\r\n",
        "    X_valid.append(token)\r\n",
        "\r\n",
        "X_test = []\r\n",
        "for stc in review_test:\r\n",
        "    token = []\r\n",
        "    words = stc.split()\r\n",
        "    for word in words:\r\n",
        "        if word not in stopwords:\r\n",
        "            token.append(word)\r\n",
        "    X_test.append(token)\r\n",
        "\r\n",
        "tokenizer = Tokenizer(5000) # 단어 수\r\n",
        "tokenizer.fit_on_texts(X_train)\r\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\r\n",
        "X_valid = tokenizer.texts_to_sequences(X_valid)\r\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\r\n",
        "\r\n",
        "# 패딩(각 문장별로 가지고 있는 단어 개수를 맞춤)\r\n",
        "X_train = pad_sequences(X_train, maxlen=200)\r\n",
        "X_valid = pad_sequences(X_valid, maxlen=200)\r\n",
        "X_test = pad_sequences(X_test, maxlen=200)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P77UHq85eB7U",
        "outputId": "62e7c4bd-2966-49a7-bbc1-cbf29166b5bf"
      },
      "source": [
        "# 모델링(함수형)\r\n",
        "\r\n",
        "input_ = Input(shape=X_train.shape[1:]) # (200, 5000)\r\n",
        "emb_vec = Embedding(5000, 256)(input_)  # (200, 5000) -> (200, 256)\r\n",
        "conv = Conv1D(256, 3, padding='valid', activation='relu')(emb_vec) # (200, 256) -> (198, 1, 256) # filters=256개, kernel size=3\r\n",
        "pool = GlobalMaxPooling1D()(conv) # (1, 256)\r\n",
        "output_ = Dense(1, activation='sigmoid')(pool)\r\n",
        "\r\n",
        "model = Model(input_, output_)\r\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_14 (Embedding)     (None, 200, 256)          1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 198, 256)          196864    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_22 (Glo (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,477,121\n",
            "Trainable params: 1,477,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWUDmP71itGW",
        "outputId": "eaf0192d-202c-4bde-99a1-5e9d90acb33d"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\r\n",
        "es = EarlyStopping(patience=5)\r\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[es])\r\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "879/879 [==============================] - 19s 21ms/step - loss: 0.4588 - acc: 0.7697 - val_loss: 0.2668 - val_acc: 0.8842\n",
            "Epoch 2/20\n",
            "879/879 [==============================] - 18s 21ms/step - loss: 0.1831 - acc: 0.9312 - val_loss: 0.2669 - val_acc: 0.8910\n",
            "Epoch 3/20\n",
            "879/879 [==============================] - 18s 20ms/step - loss: 0.0847 - acc: 0.9758 - val_loss: 0.3326 - val_acc: 0.8847\n",
            "Epoch 4/20\n",
            "879/879 [==============================] - 18s 20ms/step - loss: 0.0298 - acc: 0.9946 - val_loss: 0.3419 - val_acc: 0.8898\n",
            "Epoch 5/20\n",
            "879/879 [==============================] - 18s 20ms/step - loss: 0.0070 - acc: 0.9994 - val_loss: 0.3799 - val_acc: 0.8928\n",
            "Epoch 6/20\n",
            "879/879 [==============================] - 18s 20ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4212 - val_acc: 0.8943\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.4213 - acc: 0.8954\n",
            "[0.4213278889656067, 0.8954399824142456]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyyOh49Brc_g"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbXYaEarScy",
        "outputId": "36320810-cb6a-4edb-9bc0-9504a7da3d4c"
      },
      "source": [
        "# 모델링(서브클래스형)\r\n",
        "\r\n",
        "class CNN(Model):\r\n",
        "    \r\n",
        "    def __init__(self, activation='relu', **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        \r\n",
        "        self.emb_vec = Embedding(5000, 256)\r\n",
        "        self.conv = Conv1D(256, 3, padding='valid', activation=activation)\r\n",
        "        self.pool = GlobalMaxPooling1D()\r\n",
        "        self.output_ = Dense(1, activation='sigmoid')\r\n",
        "        \r\n",
        "    def call(self, input_):\r\n",
        "        emb_vec = self.emb_vec(input_)\r\n",
        "        conv = self.conv(emb_vec)\r\n",
        "        pool = self.pool(conv)\r\n",
        "        output_ = self.output_(pool)\r\n",
        "        \r\n",
        "        return output_\r\n",
        "\r\n",
        "model = CNN()\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\r\n",
        "es = EarlyStopping(patience=5)\r\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[es])\r\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "879/879 [==============================] - 18s 19ms/step - loss: 0.4526 - acc: 0.7792 - val_loss: 0.2837 - val_acc: 0.8795\n",
            "Epoch 2/20\n",
            "879/879 [==============================] - 17s 19ms/step - loss: 0.1751 - acc: 0.9335 - val_loss: 0.2903 - val_acc: 0.8795\n",
            "Epoch 3/20\n",
            "879/879 [==============================] - 16s 19ms/step - loss: 0.0767 - acc: 0.9777 - val_loss: 0.2941 - val_acc: 0.8897\n",
            "Epoch 4/20\n",
            "879/879 [==============================] - 17s 19ms/step - loss: 0.0233 - acc: 0.9966 - val_loss: 0.3674 - val_acc: 0.8893\n",
            "Epoch 5/20\n",
            "879/879 [==============================] - 16s 19ms/step - loss: 0.0066 - acc: 0.9995 - val_loss: 0.3880 - val_acc: 0.8895\n",
            "Epoch 6/20\n",
            "879/879 [==============================] - 17s 19ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4265 - val_acc: 0.8905\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.4224 - acc: 0.8982\n",
            "[0.42242690920829773, 0.8981599807739258]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmwraZdrbwr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxYQ3scNlSV4",
        "outputId": "750c7623-9d6b-498b-8627-013e937470ba"
      },
      "source": [
        "# 앙상블 모델 생성-------------------------------------------\r\n",
        "# CNN 모델 : Embedding → Conv → Pooling → Flatten → Dense\r\n",
        "# 함수형 API 사용\r\n",
        "\r\n",
        "# 함수형 케라스 -- 복잡한 모델을 구현할 때 사용\r\n",
        "inputs = Input(shape=(200, ))\r\n",
        "embed = Embedding(5000, 256)(inputs)\r\n",
        "\r\n",
        "\r\n",
        "# 모델 합성\r\n",
        "concat_layers = []\r\n",
        "\r\n",
        "conv = Conv1D(256, 3, padding='valid', activation='relu')(embed)\r\n",
        "pool = GlobalMaxPooling1D()(conv)\r\n",
        "flat = Flatten()(pool)\r\n",
        "concat_layers.append(flat)\r\n",
        "\r\n",
        "conv = Conv1D(256, 4, padding='valid', activation='relu')(embed)\r\n",
        "pool = GlobalMaxPooling1D()(conv)\r\n",
        "flat = Flatten()(pool)\r\n",
        "concat_layers.append(flat)\r\n",
        "\r\n",
        "conv = Conv1D(256, 5, padding='valid', activation='relu')(embed)\r\n",
        "pool = GlobalMaxPooling1D()(conv)\r\n",
        "flat = Flatten()(pool)\r\n",
        "concat_layers.append(flat)\r\n",
        "\r\n",
        "####\r\n",
        "concat = Concatenate()(concat_layers)\r\n",
        "outputs = Dense(1, activation='sigmoid')(concat)\r\n",
        "model = Model(inputs, outputs)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_15 (Embedding)        (None, 200, 256)     1280000     input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 198, 256)     196864      embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_24 (Conv1D)              (None, 197, 256)     262400      embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_25 (Conv1D)              (None, 196, 256)     327936      embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_23 (Global (None, 256)          0           conv1d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_24 (Global (None, 256)          0           conv1d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_25 (Global (None, 256)          0           conv1d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 256)          0           global_max_pooling1d_23[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 256)          0           global_max_pooling1d_24[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 256)          0           global_max_pooling1d_25[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 768)          0           flatten_12[0][0]                 \n",
            "                                                                 flatten_13[0][0]                 \n",
            "                                                                 flatten_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1)            769         concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,067,969\n",
            "Trainable params: 2,067,969\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GHKn4O781FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a398dda-11af-464f-c2ff-d7aa14ae62a0"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "es = EarlyStopping(patience=5)\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[es])\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "879/879 [==============================] - 23s 26ms/step - loss: 0.4386 - acc: 0.7871 - val_loss: 0.2712 - val_acc: 0.8870\n",
            "Epoch 2/20\n",
            "879/879 [==============================] - 23s 26ms/step - loss: 0.1507 - acc: 0.9445 - val_loss: 0.2492 - val_acc: 0.8962\n",
            "Epoch 3/20\n",
            "879/879 [==============================] - 22s 25ms/step - loss: 0.0515 - acc: 0.9865 - val_loss: 0.3156 - val_acc: 0.8938\n",
            "Epoch 4/20\n",
            "879/879 [==============================] - 22s 26ms/step - loss: 0.0135 - acc: 0.9980 - val_loss: 0.3633 - val_acc: 0.8976\n",
            "Epoch 5/20\n",
            "879/879 [==============================] - 22s 26ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4004 - val_acc: 0.8985\n",
            "Epoch 6/20\n",
            "879/879 [==============================] - 22s 25ms/step - loss: 6.3279e-04 - acc: 1.0000 - val_loss: 0.4285 - val_acc: 0.9001\n",
            "Epoch 7/20\n",
            "879/879 [==============================] - 22s 25ms/step - loss: 2.6478e-04 - acc: 1.0000 - val_loss: 0.4560 - val_acc: 0.8994\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4656 - acc: 0.9030\n",
            "[0.46563926339149475, 0.9029600024223328]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExJtSAxSGjUl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}