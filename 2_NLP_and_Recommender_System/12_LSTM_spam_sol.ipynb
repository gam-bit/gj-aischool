{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_LSTM_spam_sol.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGiWGgEFyUfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWXXX0wyy4dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjIlDEP5zIVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/mecab\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWCSN9Ijy-eK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "114be110-869a-4102-9ffa-7e555c2b3c4b"
      },
      "source": [
        "spam_data = pd.read_csv('../spam.csv', encoding='latin1')\n",
        "# 3, 4, 5열 삭제\n",
        "spam_data = spam_data.dropna(axis=1)\n",
        "\n",
        "# 칼럼명 변경\n",
        "spam_data.columns = ['label', 'mail']\n",
        "\n",
        "# ham, spam 숫자로 변경\n",
        "spam_data['label'] = spam_data['label'].replace('spam', 1)\n",
        "spam_data['label'] = spam_data['label'].replace('ham', 0)\n",
        "\n",
        "# 단어 아니면 삭제\n",
        "spam_data['mail'] = spam_data['mail'].replace(r\"[^\\w]\", \" \")\n",
        "\n",
        "# 공백이 있을 경우\n",
        "spam_data['mail'] = spam_data['mail'].replace('', np.nan)\n",
        "spam_data['label'] = spam_data['label'].replace('', np.nan)\n",
        "\n",
        "# 결측치 제거\n",
        "spam_data = spam_data.dropna(how='any', axis=0)\n",
        "\n",
        "print(\"# preproessing done\")\n",
        "\n",
        "\n",
        "# split train/test\n",
        "mail_train, mail_test, y_train, y_test = train_test_split(spam_data['mail'], spam_data\n",
        "                                                          ['label'], test_size=0.2, shuffle=False)\n",
        "\n",
        "print(\"# split done\")\n",
        "\n",
        "# 토큰화\n",
        "\n",
        "stopwords = ['a', 'an']\n",
        "\n",
        "X_train = []\n",
        "for stc in mail_train:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_train.append(token)\n",
        "\n",
        "    \n",
        "X_test = []\n",
        "for stc in mail_test:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_test.append(token)\n",
        "\n",
        "print(\"# tokenization done\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# preproessing done\n",
            "# split done\n",
            "# tokenization done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T83T208WzHTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e855dd3-63ff-41d0-de07-96dc25b5f75b"
      },
      "source": [
        "# X_train 정수 인덱스\n",
        "# 빈도수가 2개 이상인 단어\n",
        "tokenizer = Tokenizer(4000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "print(\"# int_encoding done\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# int_encoding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnuQXqevzk7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f3255dbb-fdeb-4b3e-bf48-92ef102b9ec5"
      },
      "source": [
        "# print(len(tokenizer.word_index))\n",
        "\n",
        "# low_count = 0\n",
        "# for word, word_count in tokenizer.word_counts.items():\n",
        "#     if word_count > 1:\n",
        "#         low_count += 1\n",
        "# print(low_count)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11817\n",
            "4657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_EVsx-gzlHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8208cb2d-957d-4fa8-ebda-1d2e8877a1f5"
      },
      "source": [
        "# padding\n",
        "# max_len = max([len(x) for x in X_train]) # 153\n",
        "# mean_len = np.mean([len(x) for x in X_train]) # 14\n",
        "# length 차이가 커서 50으로 잡음. 효율성을 위해 너무 큰 값(outlier)을 덜 고려함\n",
        "len = 50\n",
        "X_train = pad_sequences(X_train, maxlen=len)\n",
        "X_test = pad_sequences(X_test, maxlen=len)\n",
        "print(\"# padding done\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# padding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnuhmf502dz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 생성 SimpleRNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(4000, 32))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y4hOOKk20R3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "74d6e5ca-923b-4dca-ea2b-59c7927bf58b"
      },
      "source": [
        "# 모델 훈련\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "140/140 [==============================] - 2s 12ms/step - loss: 0.2855 - accuracy: 0.8966 - val_loss: 0.1341 - val_accuracy: 0.9641\n",
            "Epoch 2/6\n",
            "140/140 [==============================] - 1s 11ms/step - loss: 0.0965 - accuracy: 0.9726 - val_loss: 0.0779 - val_accuracy: 0.9776\n",
            "Epoch 3/6\n",
            "140/140 [==============================] - 2s 11ms/step - loss: 0.0565 - accuracy: 0.9829 - val_loss: 0.0639 - val_accuracy: 0.9839\n",
            "Epoch 4/6\n",
            "140/140 [==============================] - 2s 11ms/step - loss: 0.0525 - accuracy: 0.9816 - val_loss: 0.0596 - val_accuracy: 0.9839\n",
            "Epoch 5/6\n",
            "140/140 [==============================] - 2s 11ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.0637 - val_accuracy: 0.9848\n",
            "Epoch 6/6\n",
            "140/140 [==============================] - 2s 11ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0633 - val_accuracy: 0.9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff9d1e02fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HFs5OAO1uZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 생성 LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(4000, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# callback\n",
        "# early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "# model_check = ModelCheckpoint('LSTM_spam_best_sol.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IiYtLD02Uzh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "9699d724-626e-48df-cfbc-06f0dda8f77e"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "140/140 [==============================] - 3s 25ms/step - loss: 0.2554 - accuracy: 0.9071 - val_loss: 0.1205 - val_accuracy: 0.9659\n",
            "Epoch 2/6\n",
            "140/140 [==============================] - 3s 23ms/step - loss: 0.0860 - accuracy: 0.9809 - val_loss: 0.0687 - val_accuracy: 0.9821\n",
            "Epoch 3/6\n",
            "140/140 [==============================] - 3s 23ms/step - loss: 0.0479 - accuracy: 0.9868 - val_loss: 0.0598 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "140/140 [==============================] - 3s 24ms/step - loss: 0.0360 - accuracy: 0.9906 - val_loss: 0.0600 - val_accuracy: 0.9839\n",
            "Epoch 5/6\n",
            "140/140 [==============================] - 3s 24ms/step - loss: 0.0350 - accuracy: 0.9904 - val_loss: 0.0565 - val_accuracy: 0.9839\n",
            "Epoch 6/6\n",
            "140/140 [==============================] - 3s 24ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 0.0550 - val_accuracy: 0.9848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff9d1e02978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fepfG-iL2U4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "81c9f967-e917-4978-aeee-a3af704c11e8"
      },
      "source": [
        "sentence = input()\n",
        "# 토큰화\n",
        "token_stc = sentence.split()\n",
        "# 정수 인코딩\n",
        "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
        "# padding\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=len)\n",
        "score = model.predict(pad_stc)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU\n",
            "[[0.9974748]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3_F2Un6CiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri2fS2Ir2U9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tfCI7nx2VCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afaDOGpr1ueH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVp3Z-Hv1uiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yTxeYIK1ulB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7CAVDOo1uoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPgSK9WYzlNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJtDYC1TzlTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CwA4ky9zla7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}